{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COLX 521 Lab Assignment 2: Corpus Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment you will \n",
    "- build and access lexicons\n",
    "- calculate and compare statistics about corpora in multiple modalities\n",
    "- learn how to transform a speech signal into mathematical features that can be used for ML.\n",
    "\n",
    "Notes: \n",
    "\n",
    "- Exercises labeled with \"T\" (ie, T.3) are teamwork assignments.  Refer to the Teams folder in the repo to find your teammates.\n",
    "- Speech can be considered an alternative modality to text.  We will be working with a library called OpenSmile, that converts the speech data into numerical representations.  Once it's in this form, you can use it just like you would any numerical data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assignment requires that you have downloaded following NLTK corpora/lexicons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     /Users/jungyeul/nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n",
      "[nltk_data] Downloading package cmudict to\n",
      "[nltk_data]     /Users/jungyeul/nltk_data...\n",
      "[nltk_data]   Package cmudict is already up-to-date!\n",
      "[nltk_data] Downloading package brown to /Users/jungyeul/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /Users/jungyeul/nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#provided code\n",
    "import nltk\n",
    "nltk.download(\"treebank\")\n",
    "nltk.download(\"cmudict\")\n",
    "nltk.download(\"brown\")\n",
    "nltk.download(\"movie_reviews\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code below so you can access them and other relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#provided code\n",
    "from nltk.corpus import treebank,cmudict,brown,movie_reviews\n",
    "from collections import defaultdict, Counter\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tidy Submission\n",
    "\n",
    "rubric={mechanics:1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the marks for tidy submission:\n",
    "\n",
    "- Submit the assignment by filling in this jupyter notebook with your answers embedded\n",
    "- Be sure to follow the [general lab instructions](https://ubc-mds.github.io/resources_pages/general_lab_instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise T.3: Homophones (Lecture 3 Teamwork)\n",
    "rubric={accuracy:2,efficiency:2,quality:1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CMU pronouncing dictionary, which is accessible using NLTK, contains information about the pronunciation of words. It is a dictionary whose keys are written words and whose values are lists of pronunciations (since words can have multiple pronunciations), where each pronunciation is a list of phones, represented as strings. In this exercise, your main task is to construct sets of words that share a pronunciation: these are known as homophones. For example the word _bear_ should appear in a set with the word _bare_ because they have the same pronunciation. (side note: words that are spelled the same, but pronounced differently (like present tense \"read\" and past tense \"read\", are called \"homographs\".  Together, homophones and homographs form \"homonyms\" - you don't need to worry about homographs in this exercise.)\n",
    "\n",
    "There is an inefficient ($O(n^2)$) way to solve this problem which involves checking each pronunciation of each word against each pronunciation of every other word. You must not do this! A faster way to solve this problem is to reverse the CMU dictionary in one $O(n)$ pass, creating a lexicon which maps pronunciations to all words which have that pronunciation (this is called a \"reverse index\", and you will see them several times later in the program!).  The reverse index should have pronunciations as keys, and a list of spellings as values. The `values()` of that dictionary which have length greater than one are the sets of homophones that you want! Write code which generates and extracts those sets (you should probably have at least one function here!), then write some tests which show that the function(s) of your homophone finder are working correctly. (Hint: you may want to check that certain homophones that you know are identified correctly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['R', 'EH1', 'D'], ['R', 'IY1', 'D']] R EH1 D ~~~ R IY1 D\n",
      "[['B', 'EH1', 'R']] B EH1 R\n",
      "[['B', 'EH1', 'R']] B EH1 R\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import cmudict\n",
    "\n",
    "p_dict = cmudict.dict()\n",
    "\n",
    "print(p_dict[\"read\"], ' '.join(p_dict[\"read\"][0]), '~~~', ' '.join(p_dict[\"read\"][1]))\n",
    "print(p_dict[\"bear\"], ' '.join(p_dict[\"bear\"][0]))\n",
    "print(p_dict[\"bare\"], ' '.join(p_dict[\"bare\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a [['AH0'], ['EY1']]\n",
      "a. [['EY1']]\n",
      "a42128 [['EY1', 'F', 'AO1', 'R', 'T', 'UW1', 'W', 'AH1', 'N', 'T', 'UW1', 'EY1', 'T']]\n",
      "aaa [['T', 'R', 'IH2', 'P', 'AH0', 'L', 'EY1']]\n",
      "aaberg [['AA1', 'B', 'ER0', 'G']]\n",
      "aachen [['AA1', 'K', 'AH0', 'N']]\n",
      "aachener [['AA1', 'K', 'AH0', 'N', 'ER0']]\n",
      "aaker [['AA1', 'K', 'ER0']]\n",
      "aalseth [['AA1', 'L', 'S', 'EH0', 'TH']]\n",
      "aamodt [['AA1', 'M', 'AH0', 'T']]\n",
      "aancor [['AA1', 'N', 'K', 'AO2', 'R']]\n",
      "aardema [['AA0', 'R', 'D', 'EH1', 'M', 'AH0']]\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i, j in p_dict.items():\n",
    "    print(i, j)\n",
    "    if count > 10:\n",
    "        break \n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cheatsheet (MDS-CL 2023-2024)\n",
    "\n",
    "def build_rev_p_dict(p_dict):\n",
    "    '''given the NLTK version of the CMU pronouncing dict, reverses the dictionary. The returned\n",
    "    dict has pronunciation strings as keys and sets of homophone words as values'''\n",
    "\n",
    "    rev_p_dict = defaultdict(set)\n",
    "    ...\n",
    "\n",
    "    # rev_p_dict['AH0'].add('a')\n",
    "\n",
    "    return rev_p_dict\n",
    "\n",
    "def get_homophone_sets(p_dict):\n",
    "    '''given the NLTK version of the CMU pronouncing dict, extracts a list of sets, where each set\n",
    "    contains words which are homophones'''\n",
    "    ### Your code here\n",
    "    rev_p_dict = build_rev_p_dict(p_dict)\n",
    "    homophone = []\n",
    "    ...\n",
    "    return homophone\n",
    "    ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a', 'ae', 'ay', 'a.'}\n",
      "{'aaker', 'ocker'}\n",
      "{'encore', 'oncor', 'aancor'}\n",
      "{'aaron', 'aron', 'aran', 'ehren'}\n",
      "{'aarons', 'arens', \"aaron's\"}\n",
      "{'aaronson', 'aronson'}\n",
      "{'os', 'aase'}\n",
      "{'osten', 'aasen'}\n",
      "{'abadie', 'abadi'}\n",
      "{'abie', 'abbie', 'abby', 'abbey', 'abbe'}\n",
      "{'abet', 'abbett'}\n",
      "{'abbott', 'abbot'}\n"
     ]
    }
   ],
   "source": [
    "homophone_sets = get_homophone_sets(p_dict)\n",
    "\n",
    "count = 0\n",
    "for j in homophone_sets:\n",
    "    print(j)\n",
    "    if count > 10:\n",
    "        break \n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "# tests here\n",
    "p_dict = cmudict.dict()\n",
    "rev_p_dict = build_rev_p_dict(p_dict)\n",
    "\n",
    "assert len(rev_p_dict) == 114966\n",
    "assert \"R EH1 D\" in rev_p_dict\n",
    "assert rev_p_dict[\"R EH1 D\"] == ?\n",
    "\n",
    "homophone_sets = get_homophone_sets(p_dict)\n",
    "assert(len(homophone_sets) == 12827)\n",
    "assert {...} in homophone_sets\n",
    "assert {...} not in homophone_sets\n",
    "\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise T.4: Comparing Genres (Lecture 4 Teamwork)\n",
    "rubric={accuracy:3,efficiency:1,viz:1,reasoning:2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick 3 genres of the Brown (your choice, but best if they're fairly distinct), and do a comparison between them. You need to include at least:\n",
    "\n",
    "- average sentence length\n",
    "- percent of words in the corpus which are adjectives (JJ, JJR, JJS, JJT tags)\n",
    "- lexical density\n",
    "- 50 words strongly associated with each genre\n",
    "\n",
    "You can adapt the code from the lecture for this, or code it however you like (as long as it is fairly efficient, using functions to avoid repeating code).  For the part about individual words, you can either divide or subtract word probabilities (whichever you think is more interesting/appropriate): for each word and each genre, use the average probability of the word in the two other genres for comparison. Include at least one appropriate visualization!\n",
    "\n",
    "Then, discuss why you think you're seeing the results that you are. Were there any surprises?\n",
    "\n",
    "There's quite a bit to do here, and you are strongly advised to divide this problem among your teammates!\n",
    "\n",
    "A very thorough analysis can earn up to a bonus point (spark) for this question! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adventure',\n",
       " 'belles_lettres',\n",
       " 'editorial',\n",
       " 'fiction',\n",
       " 'government',\n",
       " 'hobbies',\n",
       " 'humor',\n",
       " 'learned',\n",
       " 'lore',\n",
       " 'mystery',\n",
       " 'news',\n",
       " 'religion',\n",
       " 'reviews',\n",
       " 'romance',\n",
       " 'science_fiction']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\"news\", \"religion\", \"fiction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average sentence length = total_word/total_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "news\n",
      "average sentence length: 21.75081116158339\n",
      "religion\n",
      "average sentence length: 22.95979020979021\n",
      "fiction\n",
      "average sentence length: 16.118616144975288\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adj_percent = adj_tokens/total_tokens\n",
    "# lex_density = open_class_tokens/total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "open_class_prefix = {\"N\", \"V\", \"J\", \"R\"}\n",
    "\n",
    "adj_percent = []\n",
    "lex_density = []\n",
    "\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HOW TO DEFINE \"strongly associated with each genre\"\n",
    "\n",
    "# 1/ prob_cat_a['word'] >> (prob_cat_b['word'] + prob_cat_c['word'])/2 \n",
    "# 2/ prob_cat_a['word'] >> prob_cat_b['word'] && prob_cat_a['word'] >> prob_cat_c['word'] \n",
    "# 3/ prob_cat_a['word'] >> average prob_cat_a[WORD] && 'word' not in cat_b && cat_c\n",
    "# 4/ ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "news\n",
      "['game', 'also', 'club', 'court', 'program', 'sales', 'three', 'other', 'board', 'meeting', 'per', 'monday', 'four', 'yesterday', 'who', 'university', 'u.s.', 'tax', 'school', 'county', 'administration', 'national', 'government', ',', 'bill', 'city', 'kennedy', 'committee', 'week', 'after', 'new', 'first', 'two', 'home', 'state', 'year', 'president', 'by', 'mr.', 'last', 'has', 'on', 'at', 'mrs.', 'said', 'will', 'a', 'for', 'in', 'the']\n",
      "religion\n",
      "['born', 'jesus', 'members', 'but', 'death', 'england', 'membership', 'its', 'new', 'life', 'if', 'human', 'faith', 'by', 'power', 'has', 'so', 'christian', 'us', 'these', 'to', 'only', 'such', 'spirit', 'can', 'christ', 'may', 'our', '(', 'be', 'it', ':', 'church', 'world', 'or', ')', 'have', 'not', 'in', 'are', 'which', 'as', 'god', 'the', 'this', ';', 'we', 'that', 'is', 'of']\n",
      "fiction\n",
      "['where', 'my', 'get', 'little', 'go', 'around', 'eyes', 'came', 'old', \"don't\", 'thought', 'went', 'now', 'about', 'looked', 'there', 'back', 'on', 'did', 'were', 'them', 'at', 'when', 'what', 'could', 'with', 'me', 'down', 'up', 'they', 'like', 'out', 'would', 'it', 'you', 'and', '``', ',', '!', \"''\", 'him', 'i', 'her', 'she', '?', 'his', 'had', 'was', 'he', '.']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Acoustic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "\n",
    "### !!! IMPORTANT !!! ###\n",
    "# !python3 -m pip install install --upgrade pip\n",
    "# !python3 -m pip install opensmile==2.5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using a function called \"process_file\" to process every file in a directory - it reads in the path_name of a file, and produces a data frame consisting of a set of features.  We will be using the extended Geneva Minimalistic Acoustic Parameter Set (eGMAPs) feature set, which consists of 88 features belonging to several different classes (you don't need to know what all of these features are, exactly, but if you are interested in learning more, you can look [here](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7160715)):\n",
    "\n",
    "   * Pitch features: Pitch is how \"high\" or \"low\" a voice sounds, in Hz (Hertz - beats / second). Pitch is indicated by the \"fundamental frequency\" of a speech signal (also written as F0, and called \"F-Zero\").  It is inversely-correlated with the length of the vocal cords, which is why men tend to have lower voices than women or children.\n",
    "   \n",
    "   * Amplitude features: Amplitude is, roughly speaking, the \"loudness\" of a signal, and is concerned with peaks in the energy wave.\n",
    "   \n",
    "   \n",
    "   * Spectral features define properties about the frequency and amplitude of the sound wave.  Some of the most important spectral features related to speech are called \"formants\", and are labeled F1-FN.  The lower formants (F1-F3), in particular, are very important for the recognition of phones.  F1 and F2 are used to determine vowel quality (/i/ -> the \"ee\" vowel, has a very low F1, and a very high F2; /ɑ/, the \"ah\" vowel, has a very high F1, and a lower F2, etc.  Other spectral features, such as *jitter* and *shimmer*, measure changes in F0's frequency and amplitude, respectively, between timesteps.\n",
    "      \n",
    "   \n",
    "   First, we'll be creating a data set by using process_file to transform the files in speech_data to a feature set.  You should get a dataframe with 250 instances with 88 features each.  Hint: you can use the os.walk function to loop through all the files in a directory.)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1/ how to read a list of files using `os.walk`, \n",
    "# 2/ how to process/extract features from audio files using `features = smile.process_file`,\n",
    "# 3/ how to put them in pandas: pandas.concat([data,features])  where `data =  pandas.DataFrame()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import opensmile\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "smile = opensmile.Smile(\n",
    "    feature_set=opensmile.FeatureSet.eGeMAPSv02,\n",
    "    feature_level=opensmile.FeatureLevel.Functionals,\n",
    ")\n",
    "### Your code here ###\n",
    "data = \n",
    "audio_files = \"./opensmile/TRAIN/\"\n",
    "for root, _, files in os.walk(audio_files):\n",
    "    for file in files:\n",
    "        # ...\n",
    "\n",
    "\n",
    "### Your code here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2\n",
    "\n",
    "rubric={accuracy:3}\n",
    "\n",
    "Next, we're going to try to identify features that might be good for learning a sentiment analysis classifier.  Read in the file Train.csv, and convert \"Negative\" to -1, \"Neutral\" to 0, and \"Positive\" to +1. This should give you a data-frame of 250 items, each with a single dependent variable.\n",
    "\n",
    "For each feature in our data set, calculate the Spearman's rank coefficient for the variable, and sort your features by the absolute value of this variable (why not rank them by just the value?).  We'll be covering rank coefficient in later classes, but it calculates a correlation in the ordering of the items: 1.0 suggests that \"Positive\" documents have a high value for the variable, \"Negative\" documents have a low value, and \"Neutral\" documents are somewhere in between; -1.0 suggests the opposite, and values close to 0 suggest no correlation.  The *spearmanr* function expects two arrays - make sure that your data is not still in a data frame when you pass it to the function.\n",
    "\n",
    "Note: make sure that your features and classes match - your functions may read the files in in different orders.  You may need to re-order the classes that you read in in the csv file.\n",
    "\n",
    "You need to do 3 operations:\n",
    "1. Read the Train.csv into a dictionary *targets* that contains the filename as the key, and the sentiment (-1, 0, 1) as the value.\n",
    "```\n",
    "# Filename,Class\n",
    "# 346.wav,Negative      --> -1\n",
    "# 163.wav,Neutral       --> 0\n",
    "# ...\n",
    "# 5.wav,Positive        --> 1\n",
    "```\n",
    "\n",
    "2. Create a numpy array *classes* that contains the sentiment scores in the same order as the data structure you created in 1.1.\n",
    "```\n",
    "for i in data.iloc:\n",
    "    print(i)\n",
    "    print(i.name[0])\n",
    "\n",
    "    print(targets[file_name])   --> append to `classes` -->  then, np.array(classes)\n",
    "\n",
    "```\n",
    "\n",
    "3. Calculate the ranked spearman correlation between your data and the classes.  Create a list containing tuples (feature_name, correlation); sort the list by the correlation, in descending order.\n",
    "```\n",
    "`spearmanr` with ith data and classes\n",
    "you may want to change the return value of `spearmanr` with `abs`, which will be your tuple with `i`:  \n",
    "`(i, abs(spearmanr_result))`\n",
    "```\n",
    "see https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.spearmanr.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F0semitoneFrom27.5Hz_sma3nz_amean             0.000000\n",
      "F0semitoneFrom27.5Hz_sma3nz_stddevNorm        0.000000\n",
      "F0semitoneFrom27.5Hz_sma3nz_percentile20.0    0.000000\n",
      "F0semitoneFrom27.5Hz_sma3nz_percentile50.0    0.000000\n",
      "F0semitoneFrom27.5Hz_sma3nz_percentile80.0    0.000000\n",
      "                                                ...   \n",
      "MeanVoicedSegmentLengthSec                    0.000000\n",
      "StddevVoicedSegmentLengthSec                  0.000000\n",
      "MeanUnvoicedSegmentLength                     2.300000\n",
      "StddevUnvoicedSegmentLength                   0.000000\n",
      "equivalentSoundLevel_dBp                     -3.807307\n",
      "Name: (./opensmile/TRAIN/275.wav, 0 days 00:00:00, 0 days 00:00:02.377142857), Length: 88, dtype: float32\n",
      "./opensmile/TRAIN/275.wav\n",
      "275.wav\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in data.iloc:\n",
    "    print(i)\n",
    "    print(i.name[0])\n",
    "    print(os.path.split(i.name[0])[-1])\n",
    "    print(targets[name])        \n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "targets = {}\n",
    "classes = []\n",
    "\n",
    "\n",
    "### Read in CSV file\n",
    "with open(\"./opensmile/TRAIN.csv\") as csvfile:\n",
    "    # ...\n",
    "\n",
    "\n",
    "### Re-order classes to be in same order as X-side data.\n",
    "for i in data.iloc:\n",
    "    # results should be appended to `classes`\n",
    "\n",
    "classes = np.array(classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       27.923246 27.616077 26.974255 28.524914  0.       26.130066\n",
      "  0.       27.718287  0.       27.052464  0.       26.84621   0.\n",
      " 27.199451 28.134117 26.715942  0.       29.521318 27.060596 27.085302\n",
      "  0.       26.078522  0.        0.       27.457468 27.08951   0.\n",
      "  0.       28.250963 27.47989   0.       27.067898 26.975119 27.03469\n",
      " 27.619026 27.576824 27.82539  26.845097  0.        0.        0.\n",
      " 27.55262   0.       28.138527  0.       29.09091  28.115582 27.35082\n",
      " 27.849318 28.134884 27.7279    0.        0.       26.738972 27.502972\n",
      " 23.198082 27.231953 27.337889 27.452139 26.916979  0.        0.\n",
      " 26.851776  0.       27.38088   0.       27.923157 30.165234  0.\n",
      "  0.       27.745296  0.       28.899874  0.       28.224504 27.71329\n",
      " 27.508121 29.334883 27.424416  0.       22.68777   0.       27.629934\n",
      " 27.539377 25.297983 27.63491  26.427753 27.309385 27.029436 26.550295\n",
      "  0.       27.867323 27.29493  26.680492 24.78723  27.548193 30.331163\n",
      " 27.925209 27.926283 29.355864  0.        0.        0.       27.501558\n",
      " 28.455153 26.12025  27.245905 27.569113  0.       27.505943  0.\n",
      " 27.9831   27.63204   0.       27.241066 28.943645 27.084143 23.518105\n",
      "  0.       27.902094 26.755352 27.654343 27.426283  0.       29.349985\n",
      " 27.125425 27.953487  0.       24.93226  27.414293 26.144115  0.\n",
      " 28.07273  29.234886  0.       23.677872 28.025309 26.98222  28.926344\n",
      " 27.08186   0.        0.       28.47469  24.176233 25.917297 27.663965\n",
      " 26.862574 28.13592  28.714151 27.414896 26.49876  23.978762  0.\n",
      " 27.934822  0.        0.       27.730354  0.        0.        0.\n",
      "  0.       26.097311 27.683771 27.159155 27.31695  24.668568 27.666035\n",
      " 25.762636 27.929667 28.085865 27.987934  0.        0.       27.05719\n",
      "  0.       27.176136 28.559511  0.        0.        0.       24.65366\n",
      " 27.975538 26.136497  0.        0.       27.506947 28.562626  0.\n",
      " 28.089722 27.422052  0.        0.       28.049028 27.478426  0.\n",
      " 27.860937 28.838047 27.303223 27.526638  0.       28.388027 28.294258\n",
      " 27.33249   0.       26.774551 28.65824  27.72968   0.       28.041462\n",
      " 27.34602  27.814842 27.43467  27.746944  0.       27.444305  0.\n",
      " 27.2452   27.879694 27.748478 27.615725 26.909002  0.       28.213703\n",
      " 26.972303 27.846216 27.094494 27.899122 27.609661 28.518448  0.\n",
      " 27.962326 28.3399    0.        0.       28.135479  0.       27.383522\n",
      " 27.130487 26.676714 27.434696 27.58307  27.735415 29.36098  27.70817\n",
      "  0.       27.893187 27.725971  0.        0.      ] [-1 -1  1  1  1 -1 -1 -1 -1  1  1  1 -1 -1 -1 -1 -1  1  1  1 -1 -1 -1 -1\n",
      "  1  0  1  1 -1 -1 -1  1  1  1  1  0 -1 -1 -1  1  1  1  1 -1 -1 -1 -1 -1\n",
      " -1  1 -1 -1 -1  1  1 -1  0  1  0  0  0  0  0  1  1  1  0  0  0  0  0  1\n",
      "  1  0  1  0 -1  0  1  0  1  0  0  0  0  0  1  1  1  0  0  0  1  0  0  0\n",
      "  1  1  1  0  0  0  0  1  0  0  1  1  1  1  0  1  1  0  0 -1 -1 -1  0  0\n",
      "  1  0  1  1  0  0  1  0  0  0  0  0  1  1  0  1  0 -1 -1 -1  0  0  0  0\n",
      "  0  0  1  1  0  0  1  1 -1 -1  1  1  1  1  0  0  0  0  0  0  1  0  0  1\n",
      "  0  0 -1 -1 -1 -1  1  0  0  0  1  1  1  0  1  0  0  0 -1 -1 -1  0  1  0\n",
      " -1 -1 -1  0  1  1 -1 -1 -1 -1 -1 -1  1  1  0 -1 -1 -1  1  1  1 -1 -1 -1\n",
      " -1 -1 -1 -1  1  1 -1 -1 -1  1  1  1 -1 -1 -1 -1 -1 -1 -1 -1  1  0  0 -1\n",
      " -1 -1 -1 -1  0 -1 -1 -1 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "correlations = []\n",
    "import math\n",
    "\n",
    "for i in data:\n",
    "    print(np.array(data[i]), classes)\n",
    "#     cor, p = spearmanr(X, classes)\n",
    "#     cor = abs(cor)\n",
    "#     correlations.append((i, cor))\n",
    "# correlations = sorted(correlations, key=lambda x: x[1], reverse=True)\n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "correlations = []\n",
    "import math\n",
    "\n",
    "for i in data:\n",
    "    # ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mfcc1V_sma3nz_amean', 0.2099267483028794),\n",
       " ('F1frequency_sma3nz_amean', 0.20881643142591008),\n",
       " ('mfcc1_sma3_amean', 0.19975211351481237),\n",
       " ('slopeUV0-500_sma3nz_amean', 0.18745066968212662),\n",
       " ('mfcc4_sma3_stddevNorm', 0.18063979974674654),\n",
       " ('slopeUV500-1500_sma3nz_amean', 0.1565102795593888),\n",
       " ('loudness_sma3_percentile20.0', 0.15471949736123558),\n",
       " ('F3frequency_sma3nz_amean', 0.1538476882641244),\n",
       " ('F3frequency_sma3nz_stddevNorm', 0.15040186301773548),\n",
       " ('slopeV500-1500_sma3nz_amean', 0.14964774009236556),\n",
       " ('F2frequency_sma3nz_amean', 0.14515895250973904),\n",
       " ('alphaRatioV_sma3nz_amean', 0.14070446202454023),\n",
       " ('shimmerLocaldB_sma3nz_stddevNorm', 0.12773159485993074),\n",
       " ('hammarbergIndexV_sma3nz_amean', 0.12114685212987819),\n",
       " ('logRelF0-H1-A3_sma3nz_amean', 0.11641715842917456),\n",
       " ('loudness_sma3_pctlrange0-2', 0.11638525676944124),\n",
       " ('StddevUnvoicedSegmentLength', 0.11586895474416674),\n",
       " ('F1frequency_sma3nz_stddevNorm', 0.1153874190702585),\n",
       " ('slopeV0-500_sma3nz_amean', 0.11485106205265291),\n",
       " ('mfcc1_sma3_stddevNorm', 0.11410437509181738),\n",
       " ('F0semitoneFrom27.5Hz_sma3nz_percentile50.0', 0.1134539718550224),\n",
       " ('F1amplitudeLogRelF0_sma3nz_amean', 0.1095684826126918),\n",
       " ('F1bandwidth_sma3nz_amean', 0.10481936766404713),\n",
       " ('F1amplitudeLogRelF0_sma3nz_stddevNorm', 0.10466854307897316),\n",
       " ('loudnessPeaksPerSec', 0.1024026956230331),\n",
       " ('slopeV500-1500_sma3nz_stddevNorm', 0.0988971266961558),\n",
       " ('F2bandwidth_sma3nz_amean', 0.09645211554579207),\n",
       " ('F2amplitudeLogRelF0_sma3nz_amean', 0.0958310488297203),\n",
       " ('mfcc1V_sma3nz_stddevNorm', 0.08933360834834132),\n",
       " ('F0semitoneFrom27.5Hz_sma3nz_percentile80.0', 0.08800841808989676),\n",
       " ('F3amplitudeLogRelF0_sma3nz_amean', 0.08689438225055578),\n",
       " ('F0semitoneFrom27.5Hz_sma3nz_amean', 0.08208369781375763),\n",
       " ('spectralFlux_sma3_amean', 0.08184287418491555),\n",
       " ('F0semitoneFrom27.5Hz_sma3nz_percentile20.0', 0.08079693683315384),\n",
       " ('MeanUnvoicedSegmentLength', 0.07816741739697997),\n",
       " ('hammarbergIndexUV_sma3nz_amean', 0.07590785629577429),\n",
       " ('F2amplitudeLogRelF0_sma3nz_stddevNorm', 0.07175779217974727),\n",
       " ('equivalentSoundLevel_dBp', 0.07139109587804453),\n",
       " ('loudness_sma3_stddevRisingSlope', 0.06881171769365314),\n",
       " ('mfcc2_sma3_stddevNorm', 0.06855558758390518),\n",
       " ('mfcc2V_sma3nz_amean', 0.06828965315912824),\n",
       " ('slopeV0-500_sma3nz_stddevNorm', 0.06427606632399507),\n",
       " ('alphaRatioUV_sma3nz_amean', 0.06369725665207056),\n",
       " ('mfcc4V_sma3nz_stddevNorm', 0.06227567778606861),\n",
       " ('loudness_sma3_percentile50.0', 0.05869308617021104),\n",
       " ('F0semitoneFrom27.5Hz_sma3nz_stddevNorm', 0.058119530726687435),\n",
       " ('F3amplitudeLogRelF0_sma3nz_stddevNorm', 0.055672453486117206),\n",
       " ('MeanVoicedSegmentLengthSec', 0.05153249737213048),\n",
       " ('F3bandwidth_sma3nz_stddevNorm', 0.049652279842438106),\n",
       " ('mfcc4_sma3_amean', 0.048659080704672),\n",
       " ('jitterLocal_sma3nz_amean', 0.047778546828436415),\n",
       " ('loudness_sma3_percentile80.0', 0.04435966559025119),\n",
       " ('spectralFluxV_sma3nz_amean', 0.04335442367500635),\n",
       " ('HNRdBACF_sma3nz_amean', 0.04053627663335),\n",
       " ('spectralFlux_sma3_stddevNorm', 0.03929072279427449),\n",
       " ('mfcc3V_sma3nz_amean', 0.03922596222439218),\n",
       " ('loudness_sma3_amean', 0.038310990621621265),\n",
       " ('shimmerLocaldB_sma3nz_amean', 0.037975856837096894),\n",
       " ('logRelF0-H1-A3_sma3nz_stddevNorm', 0.03428965950303927),\n",
       " ('logRelF0-H1-H2_sma3nz_amean', 0.03302025368017002),\n",
       " ('StddevVoicedSegmentLengthSec', 0.03270718369037839),\n",
       " ('F0semitoneFrom27.5Hz_sma3nz_meanRisingSlope', 0.0286853310242456),\n",
       " ('mfcc2V_sma3nz_stddevNorm', 0.027950894749518958),\n",
       " ('F1bandwidth_sma3nz_stddevNorm', 0.02745379344583676),\n",
       " ('loudness_sma3_meanFallingSlope', 0.026384329990116806),\n",
       " ('F2bandwidth_sma3nz_stddevNorm', 0.02620008990853685),\n",
       " ('mfcc2_sma3_amean', 0.022038881721637853),\n",
       " ('mfcc3V_sma3nz_stddevNorm', 0.020953047220127405),\n",
       " ('loudness_sma3_stddevNorm', 0.016557270031316986),\n",
       " ('loudness_sma3_stddevFallingSlope', 0.013160840618425654),\n",
       " ('VoicedSegmentsPerSec', 0.012905092719723753),\n",
       " ('HNRdBACF_sma3nz_stddevNorm', 0.012131255256443891),\n",
       " ('spectralFluxV_sma3nz_stddevNorm', 0.01131349675271399),\n",
       " ('F0semitoneFrom27.5Hz_sma3nz_stddevRisingSlope', 0.010708965411867014),\n",
       " ('F0semitoneFrom27.5Hz_sma3nz_pctlrange0-2', 0.010307310822151932),\n",
       " ('alphaRatioV_sma3nz_stddevNorm', 0.009419718469442569),\n",
       " ('mfcc4V_sma3nz_amean', 0.009078813585371236),\n",
       " ('F2frequency_sma3nz_stddevNorm', 0.008951955646692569),\n",
       " ('F0semitoneFrom27.5Hz_sma3nz_meanFallingSlope', 0.008526754282196325),\n",
       " ('jitterLocal_sma3nz_stddevNorm', 0.007715972611456989),\n",
       " ('logRelF0-H1-H2_sma3nz_stddevNorm', 0.007009417634547917),\n",
       " ('F3bandwidth_sma3nz_amean', 0.005899513975619913),\n",
       " ('loudness_sma3_meanRisingSlope', 0.0057981405461011385),\n",
       " ('mfcc3_sma3_stddevNorm', 0.0034651151187477186),\n",
       " ('spectralFluxUV_sma3nz_amean', 0.0024202032589325413),\n",
       " ('F0semitoneFrom27.5Hz_sma3nz_stddevFallingSlope', 0.0013182430447203134),\n",
       " ('mfcc3_sma3_amean', 0.0009581414012808175),\n",
       " ('hammarbergIndexV_sma3nz_stddevNorm', 0.0007710648650631616)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.3 Optional (Feature selection)\n",
    "\n",
    "rubric={accuracy:1, reasoning:1}\n",
    "\n",
    "When selecting features, we often try to increase efficiency by eliminating features that are unlikely to have an impact on the model.  There are several ways of selecting features, but we're going to select features that have a high correlation with the class ordering (that's why we linearized the classes to [-1, 0, 1]).\n",
    "\n",
    "Train an sklearn decision tree classifier (max_depth=5) using the features you've extracted.  Train one with all of the features, one with the 20 that you've identified as the best, and one with the 20 you've identified as the worst.  Run each model 100 times, and average the accuracies (you can use the metrics.accuracy_score() function to calculate the accuracy of your classifier).  Can we note any trends?  Explain briefly what this might mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(data, classes, test_size=0.20,random_state=42) # 80% training and 20% test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn import metrics\n",
    "\n",
    "# clf = DecisionTreeClassifier(max_depth=5)\n",
    "\n",
    "# ### Your code here ###\n",
    "\n",
    "# ### Your code here ###\n",
    "\n",
    "# print(\"Full Average Accuracy:\",np.average(full_scores))\n",
    "# print(\"Best Average Accuracy:\", np.average(best_scores))\n",
    "# print(\"Worst Average Accuracy:\", np.average(worst_scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis Answer: \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Readability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Flesh Reading Ease](https://en.wikipedia.org/wiki/Flesch%E2%80%93Kincaid_readability_tests) is calculated using the following formula:\n",
    "\n",
    "\\begin{equation*}\n",
    "206.835-1.015 \\left({\\frac {\\text{total words}}{\\text{total sentences}}}\\right) -84.6\\left({\\frac {\\text{total syllables}}{\\text{total words}}}\\right)\n",
    "\\end{equation*}\n",
    "\n",
    "Scores above 70 indicate text which are appropriate for primary school school students, scores between 70 and 50 indicate texts which can be read by secondary school students, and scores below 50 are appropriate only for college students.\n",
    "\n",
    "#### 2.1\n",
    "\n",
    "rubric={accuracy:3}\n",
    "\n",
    "First, write a function which uses the CMU dictionary to count the number of syllables in a word. The number of syllables can be most easily determined by counting the number of ARPAbet phones in the word which end with a digit (0,1, or 2), indicating the level of stress on a vowel. \n",
    "- For our purposes here, just use the first pronounciation provided. \n",
    "- If a word does not appear in the CMU, you can default to the guess that the number of syllables is equal to the number of vowels (be careful about case here, be sure to lowercase before you check the vowels!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vowels = {\"a\",\"e\",\"i\",\"o\",\"u\",\"y\"}\n",
    "p_dict = cmudict.dict() # keep this outside as a global variable so you aren't reloading each time\n",
    "\n",
    "def get_syllables(word):\n",
    "    '''use CMU dict (p_dict) to count the number of syllables in word, default to number of vowels'''\n",
    "    syllable_count = 0\n",
    "    #your code here\n",
    "    # ...\n",
    "\n",
    "    #your code here\n",
    "    return syllable_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "assert get_syllables(\"readability\") == 5\n",
    "assert get_syllables(\"blabglob\") == 2\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Code Review\n",
    "\n",
    "rubric={accuracy:3, reasoning:1}\n",
    "\n",
    "A function has been provided which calculates the reading ease of the sentence; however, it is not very good code.  Perform a code review, explaining in a few sentences how this code could be improved.  Secondly, write a function that correctly calculates the reading ease of a sentence.  You can use the formula provided above to calculate the reading ease.  The number of sentences will be 1 (this function calculates the reading ease for a single sentence), and the number of syllables will be calculated using the function you wrote in 2.1.  You should exclude words that have non-alphabetic characters (you can use _isalpha_).  If your sentence has no words, return None.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reading_ease(sentence):\n",
    "    '''calculate the Flesh reading ease for a single sentence consisting of a list of words (strings)'''\n",
    "    total_syllables = 0\n",
    "    num_words = 0\n",
    "    for word in sentence:\n",
    "        if not word.isalpha():\n",
    "            sentence.remove(word)\n",
    "        else:\n",
    "            num_words += 1\n",
    "            total_syllables += get_syllables(word)\n",
    "    print(\"Syllables: \", total_syllables)\n",
    "    reading_ease = 206.835 - 1.015 * num_words - 846 * (total_syllables/num_words) \n",
    "    return reading_ease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Syllables:  3\n",
      "-642.21\n",
      "['This', 'is', 'a', 'test']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"This is a fea342 test\".split(\" \")\n",
    "print(get_reading_ease(sentence))\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your written answer here:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reading_ease(sentence):\n",
    "    '''calculate the Flesh reading ease for a single sentence consisting of a list of words (strings)'''\n",
    "    # your code here\n",
    "    \n",
    "    # ...\n",
    "    # your code here\n",
    "    return reading_ease\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "assert 100 < get_reading_ease([\"I\", \"am\", \"done\", \",\",\"man\"]) < 140\n",
    "assert -60 < get_reading_ease([\"Felicitations\", \"for\", \"achieving\", \"a\", \"thoroughly\", \"excellent\", \"resolution\", \"to\", \"an\", \"altogether\", \"indombidable\", \"conundrum\", \"of\", \"humongous\", \"proportions\", \".\"]) <-20\n",
    "assert get_reading_ease([\"?\"]) == None\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3\n",
    "\n",
    "rubric={accuracy:2,quality:1}\n",
    "\n",
    "Finally, use the function you just wrote to calculate the average reading ease (across all sentences) for two NLTK corpora: the Penn Treebank (treebank), and the Movie Review corpus (movie_reviews). You should print out your results, and it should be clear which is which. Note the quality point for this problem, make sure to document and avoid repeated code! Save the result in variables `penn_readability` and `review_readability` and run the tests to confirm your results are correct.\n",
    "\n",
    "Note, if `get_reading_ease` returns None, you should skip over that sentence for the purposes of these calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treebank readability\n",
      "47.123132451339806\n",
      "Movie review readability\n",
      "59.39520661660777\n"
     ]
    }
   ],
   "source": [
    "def calculate_avg_reading_ease(corpus):\n",
    "    '''calculate and return average Flesh reading ease for all sentences in a corpus'''\n",
    "    total_sents = 0\n",
    "    total_ease = 0\n",
    "    \n",
    "\n",
    "    # ...\n",
    "    return total_ease/total_sents\n",
    "\n",
    "\n",
    "penn_readability = calculate_avg_reading_ease(treebank)\n",
    "review_readability = calculate_avg_reading_ease(movie_reviews)\n",
    "\n",
    "print(\"Treebank readability\")\n",
    "print(penn_readability)\n",
    "print(\"Movie review readability\")\n",
    "print(review_readability)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "assert 40 < penn_readability < 50\n",
    "assert 55 < review_readability < 65\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 \n",
    "\n",
    "rubric={reasoning:1}\n",
    "\n",
    "Do these results make sense given the genre of these texts? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
