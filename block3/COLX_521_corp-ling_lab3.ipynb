{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COLX 521 Lab Assignment 3: Regex soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment you will \n",
    "- practice regular expressions\n",
    "- extract data from XML documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import zipfile\n",
    "import io\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Tag, NavigableString\n",
    "from urllib.request import urlopen\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tidy Submission\n",
    "\n",
    "rubric={mechanics:1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the marks for tidy submission:\n",
    "\n",
    "- Submit the assignment by filling in this jupyter notebook with your answers embedded\n",
    "- Be sure to follow the [general lab instructions](https://ubc-mds.github.io/resources_pages/general_lab_instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise T.5: Noun coordination with regex (Lecture 5 Teamwork)\n",
    "rubric={accuracy:3, quality:2, efficiency:1}\n",
    "\n",
    "You're going to use regular expressions to write a function `extract_noun_coordination` which extracts all instances of simple noun coordination in a provided passage of text. By noun coordination, we mean cases such as"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "He's counting his dollars and cents. (dollars, cents)\n",
    "You need either a hammer or a rock. (a hammer, a rock)\n",
    "Tom, Bill, and Jerry are all here. (Tom, Bill, Jerry) \n",
    "My favourite colours are as follows: purple; dark blue; light green; and hot pink. (purple, dark blue, light green, hot pink)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should not extract any tuples in cases such as:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Mary likes red ballons, and Annie likes them even more.\n",
    "Jill is running and jumping.\n",
    "I love staying up late; my partner prefers to head to bed early."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given an passage, you should return a lists of these coordinations (in the order that they appear), and each coordination should be a tuple of strings corresonding to noun phrases being coordinated (not necessarily individual words!).\n",
    "\n",
    "Note that it isn't actually possible to fully capture even simple English noun coordination using regex (certainly not without part-of-speech tagging, which you SHOULD NOT do here), but you should be able to solve the problem for the provided passage. A few rules which you must follow to get full points:\n",
    "\n",
    "* Do not tokenize or POS tag the text\n",
    "* Use ONLY regular expressions, not string methods. You can leave the case of the words as is, no need to lower case them.\n",
    "* Your regexes should generalize to more cases than provided in this example. Do NOT hard code solutions that only work here (e.g. don't have a regex that just matches \"dollars and cents\" and nothing else).\n",
    "* It will be useful to develop different regexes for different cases, but in the end you shouldn't don't have more regex calls than you need, remember that two otherwise independent regexes can be put together into a single regex that matches either with the | (OR) operator. Note that regexes are greedy, so if mutiple ORed regexes both have matches within a single span, the one that covers the most text will win out!\n",
    "* This problem breaks down naturally into two parts, and so you'll probably want to have a function for each part.\n",
    "* Use compiled regexes for anything likely to be used more than once. Since we aren't going so far as to create a class here (if we had, we would probably have the compiled regexes be class variables for our CoordinationExtractor class), it's okay to just include compiled regexes as global variables.\n",
    "* Don't forget to document, and also you should add a few new test cases in addition to the big provided one. You test cases should demonstrate specific functionalities. (you might want to do this first, to help with debugging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#provided code\n",
    "test_case = '''\n",
    "Peas and beans are two popular garden vegetables, but they belong to a class of their own. Like tomatoes, cucumbers, and peppers, they are biological fruits; however, because their seeds are contained in a hard pod, they are also legumes. We usually think of the seed as the legume, but it can also apply to the stem, the leaf, or the pod. Because they restore nitrogen to the soil, beans, peas, and peanuts are often alternated with crops like tomatoes, corn, or potatoes.  These plants produce high climbing vines, so your toolkit should include: stakes; twine; and soil. With a bit of light and fertilizer, you'll have your plants sprouting and climbing in no time! As fun as gardening can be, don't forget that patience, attention, and shade can be just as effective as sun, water, or soil.  Good luck, and have fun!\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #provided code\n",
    "# '''\n",
    "# [Peas and beans] are two popular garden vegetables, but they belong to a class of their own. \n",
    "# Like [tomatoes, cucumbers, and peppers], they are biological fruits; \n",
    "# however, because their seeds are contained in a hard pod, they are also legumes. \n",
    "# We usually think of the seed as the legume, but it can also apply to *[the stem, the leaf, or the pod]. \n",
    "# Because they restore nitrogen to the *[soil, [beans, peas, and peanuts]] are often alternated with crops like [tomatoes, corn, or potatoes].  \n",
    "# These plants produce high climbing vines, so your toolkit should include:\n",
    "# [stakes; twine; and soil]. With a bit of [light and fertilizer], you'll have your plants sprouting and climbing in no time! \n",
    "# As fun as gardening can be, don't forget that [patience, attention, and shade] can be just as effective as [sun, water, or soil].  \n",
    "# Good luck, and have fun!\n",
    "# '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Dogs and cats are definitely the two most popular pets; they're way more popular than second tier choices such as hamsters, snakes, frogs, and fish. Head to a store or a shelter to get one of your own!  If you get a dog, you'll need to buy at least a leash and a bowl, to start. Oh, and don't forget the poop bags; your neighbors will thank you! A scratching post will hopefully give your new feline friend a better option than clawing and chewing your couch or chair straight to the dump heap. But the most important things that you will bring to this relationship are most certainly love, patience and care! Good luck, and enjoy your new pet!\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(1, 15), match='Peas and beans'>\n",
      "<re.Match object; span=(589, 609), match='light and fertilizer'>\n",
      "<re.Match object; span=(635, 657), match='sprouting and climbing'>\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "regex = r\"\" #handles A, B, and C \n",
    "for re_result in re.finditer(regex, test_case, re.IGNORECASE):\n",
    "    print(re_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "<re.Match object; span=(635, 657), match='sprouting and climbing'>\n"
     ]
    }
   ],
   "source": [
    "print(\"-\")\n",
    "regex = r\"\" # exclude Aing and Bing\n",
    "for re_result in re.finditer(regex, test_case, re.IGNORECASE):\n",
    "    print(re_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_to_tuple(nouns):\n",
    "    '''given a string of corresponding to a noun coordination, splits them into individual nouns\n",
    "    and puts them into a tuple. For example \"dollars and cents\" becomes (\"dollars\", \"cents\")'''\n",
    "    return ...\n",
    "\n",
    "def extract_noun_coordination(passage):\n",
    "    '''Given a passage, extracts all instances of noun coordination and returns a lists of tuples\n",
    "    where each tuple in the lists corresponds to an instance of coordination, and the elements of\n",
    "    each tuple consists of the nouns being coordinated, as strings'''\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Peas', 'beans'),\n",
       " ('tomatoes', 'cucumbers', 'peppers'),\n",
       " ('soil', 'beans', 'peas', 'peanuts'),\n",
       " ('tomatoes', 'corn', 'potatoes'),\n",
       " ('stakes', 'twine', 'soil'),\n",
       " ('light', 'fertilizer'),\n",
       " ('patience', 'attention', 'shade'),\n",
       " ('sun', 'water', 'soil')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_noun_coordination(test_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "assert extract_noun_coordination(test_case) == [\n",
    "    ('Peas', 'beans'), \n",
    "    ('tomatoes', 'cucumbers', 'peppers'), \n",
    "    ('soil', 'beans', 'peas', 'peanuts'), \n",
    "    ('tomatoes', 'corn', 'potatoes'), \n",
    "    ('stakes', 'twine', 'soil'), \n",
    "    ('light', 'fertilizer'), \n",
    "    ('patience', 'attention', 'shade'), \n",
    "    ('sun', 'water', 'soil')]\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "# add a few more specific tests\n",
    "#your code here\n",
    "\n",
    "assert split_to_tuple(\"dollars and cents\") == (\"dollars\", \"cents\")\n",
    "assert extract_noun_coordination(\"He's counting his dollars and cents.\") == [(\"dollars\", \"cents\")]\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise T.5.2: Too greedy (and also not greedy enough). \n",
    "rubric={accuracy:2}\n",
    "\n",
    "You may have noticed that there are a few things missing from the return in the previous part if you only follow the rules provided - \"... restore nitrogen to the soil, beans, peas, and peanuts...\" returns (soil, beans, peas, peanuts).  Soil should be excluded.  Likewise, it misses \"(the stem, the leaf, the pod)  Fix your regex so that it only includes items if they all have \"the\" before the noun, or none of them do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Peas', 'beans'),\n",
       " ('tomatoes', 'cucumbers', 'peppers'),\n",
       " ('the stem', 'the leaf', 'the pod'),\n",
       " ('beans', 'peas', 'peanuts'),\n",
       " ('tomatoes', 'corn', 'potatoes'),\n",
       " ('stakes', 'twine', 'soil'),\n",
       " ('light', 'fertilizer'),\n",
       " ('patience', 'attention', 'shade'),\n",
       " ('sun', 'water', 'soil')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_noun_coordination(test_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "assert extract_noun_coordination(test_case) == [\n",
    "    ('Peas', 'beans'), \n",
    "    ('tomatoes', 'cucumbers', 'peppers'), \n",
    "    ('the stem', 'the leaf', 'the pod'), \n",
    "    ('beans', 'peas', 'peanuts'), \n",
    "    ('tomatoes', 'corn', 'potatoes'), \n",
    "    ('stakes', 'twine', 'soil'), ('light', 'fertilizer'), \n",
    "    ('patience', 'attention', 'shade'), \n",
    "    ('sun', 'water', 'soil')]\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise T.6:  Parsing the BNC (Lecture 6 teamwork)\n",
    "rubric={accuracy:3,quality:1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [British National Corpus](http://www.natcorp.ox.ac.uk/) (BNC) is a popular corpus which, like the Brown, covers a diverse set of genres, but is about 100 times bigger. It is available in XML format. I've put a small sample of online for you to access, see the asserts below.\n",
    "You are going to write a function, `read_BNC_XML` which, given a (string) URL to a BNC XML document, converts that document from an XML format to the space delimited, POS-tagged format we saw back in lab 1. For each sentence (indicated by the s tag) in the xml, you'll be creating a string consisting of word/POS tags, like this:\n",
    "\n",
    "Violence/NN1 erupts/VVZ on/II Basque/JJ funeral/NN1 day/NNT1 ./YSTP\n",
    "\n",
    "The source sentence inside the XML looks like this:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<s n=\"0001\" p=\"Y\"><w type=\"NN1\">Violence </w>\n",
    "<w type=\"VVZ\">erupts </w><w type=\"II\">on </w>\n",
    "<w type=\"JJ\">Basque </w><w type=\"NN1\">funeral </w>\n",
    "<w type=\"NNT1\">day</w><c type=\"YSTP\">. </c></s>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, each sentence is contained in an <s\\> tag, and each word is contained within an XML <w\\> tag, punctuation (which should also be included in the output) are in <c\\> tags, and the part-of-speech appears as the type attribute. You must solve this problem using Beautiful Soup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "\n",
    "\n",
    "def read_BNC_XML(url):\n",
    "    '''given a URL corresponding to a text in the BNC corpus, this function reads the XML\n",
    "    formatted text into a list of sentences, where each sentence is a string with token separated \n",
    "    by space in word/POS format'''\n",
    "    page = BeautifulSoup(urlopen(url),\"lxml\")\n",
    "    sents = []\n",
    "\n",
    "    # ...\n",
    "    \n",
    "    return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "path = \"https://garrettnicolai.github.io/Garrett-Nicolai/COLX521/Lab3/\"\n",
    "assert len(read_BNC_XML(path+ \"A9E.xml\")) == 900\n",
    "assert read_BNC_XML(path+ \"A7V.xml\")[0] ==\"Lebanon/NP1 leader/NN1 builds/VVZ cabinet/NN1 ./YSTP\"\n",
    "assert read_BNC_XML(path+ \"A8J.xml\")[2] == \"PROTESTERS/NN2 set/VVD fire/NN1 to/II banks/NN2 and/CC offices/NN2 of/IO the/AT ruling/JJ Socialist/JJ Party/NN1 yesterday/RT as/CSA Basques/NN2 mourned/VVD the/AT assassination/NN1 of/IO one/MC1 of/IO their/APPGE leaders/NN2 ./YSTP\"\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Regex Potpourri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write regular expressions that match the strings described. They should correctly match the correct answers, and should not match the incorrect answers. You should modify and run the box for each subexercise, then run the box at the bottom (before exercise 2, code is provided) to see if your regex is correct. A completed example is provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A three digit number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good forms\n",
      "<re.Match object; span=(0, 3), match='911'>\n",
      "<re.Match object; span=(0, 3), match='512'>\n",
      "-\n",
      "bad forms\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "positive_examples = [\"911\",\"512\"]\n",
    "negative_examples = [\"huh\",\"2020\",\"3\"]\n",
    "\n",
    "regex = \"^[0-9]{3}$\"\n",
    "\n",
    "print(\"good forms\")\n",
    "for form in positive_examples:\n",
    "    print(re.match(regex,form))\n",
    "\n",
    "print(\"-\")\n",
    "print(\"bad forms\")\n",
    "for form in negative_examples:\n",
    "    print(re.match(regex,form))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1\n",
    "rubric={accuracy:1}\n",
    "\n",
    "A Canadian zip code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good forms\n",
      "<re.Match object; span=(0, 6), match='V5B2L8'>\n",
      "<re.Match object; span=(0, 7), match='M6E 3L7'>\n",
      "-\n",
      "bad forms\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "positive_examples = [\"V5B2L8\",\"M6E 3L7\"]\n",
    "negative_examples = [\"huh\", \"90210\", \"AAA AAA\", \"S4D2?X\", \"M6E 3L7 D3Z\"]\n",
    "\n",
    "#your code here\n",
    "regex = r\"\"\n",
    "\n",
    "print(\"good forms\")\n",
    "for form in positive_examples:\n",
    "    print(re.match(regex,form))\n",
    "\n",
    "print(\"-\")\n",
    "print(\"bad forms\")\n",
    "for form in negative_examples:\n",
    "    print(re.match(regex,form))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2\n",
    "rubric={accuracy:1}\n",
    "\n",
    "A valid XML closing tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good forms\n",
      "<re.Match object; span=(0, 4), match='</p>'>\n",
      "<re.Match object; span=(0, 5), match='</h2>'>\n",
      "<re.Match object; span=(0, 55), match='</some_text_which_is_not_that_important_or_intere>\n",
      "-\n",
      "bad forms\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "positive_examples = [\"</p>\",\"</h2>\",\"</some_text_which_is_not_that_important_or_interesting>\"]\n",
    "negative_examples = [\"huh\",\"<p>\",\"</2>\",\"</p>>\",\"</huh?>\"]\n",
    "\n",
    "#your code here\n",
    "regex = r\"\"\n",
    "\n",
    "print(\"good forms\")\n",
    "for form in positive_examples:\n",
    "    print(re.match(regex,form))\n",
    "\n",
    "print(\"-\")\n",
    "print(\"bad forms\")\n",
    "for form in negative_examples:\n",
    "    print(re.match(regex,form))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3\n",
    "rubric={accuracy:1}\n",
    "\n",
    "A single English word, including words with (multiple) internal hyphens and those with a single apostrophe within 2 letters of the end of the word (`..'ll`, `..'ve`, `..'re`).  That is, if you have `'`, then any character(s) up to two. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print up to two characters:\n",
      "None\n",
      "<re.Match object; span=(0, 2), match='No'>\n",
      "<re.Match object; span=(0, 1), match='X'>\n",
      "<re.Match object; span=(0, 0), match=''>\n"
     ]
    }
   ],
   "source": [
    "# lab3 regex!\n",
    "S1 = 'Yes'\n",
    "S2 = 'No'\n",
    "S3 = 'X'\n",
    "S4 = ''\n",
    "\n",
    "print(\"print up to two characters:\")\n",
    "regex2 = r'[A-Za-z]{,2}$'\n",
    "print(re.match(regex2, S1))\n",
    "print(re.match(regex2, S2))\n",
    "print(re.match(regex2, S3))\n",
    "print(re.match(regex2, S4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good forms\n",
      "<re.Match object; span=(0, 4), match='word'>\n",
      "<re.Match object; span=(0, 13), match='forget-me-not'>\n",
      "<re.Match object; span=(0, 8), match=\"doctors'\">\n",
      "<re.Match object; span=(0, 5), match=\"he'll\">\n",
      "-\n",
      "bad forms\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "positive_examples = [\"word\", \"forget-me-not\", \"doctors'\", \"he'll\"]\n",
    "negative_examples = [\"huh?\",\"243\", \"--word--\", \"'sorry'\",\"\"]\n",
    "\n",
    "#your code here\n",
    "regex = r\"\"\n",
    "\n",
    "print(\"good forms\")\n",
    "for form in positive_examples:\n",
    "    print(re.match(regex,form))\n",
    "\n",
    "print(\"-\")\n",
    "print(\"bad forms\")\n",
    "for form in negative_examples:\n",
    "    print(re.match(regex,form))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4\n",
    "rubric={accuracy:2}\n",
    "\n",
    "A English sentence which contains a form of the phrase \"leave X alone\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good forms\n",
      "<re.Match object; span=(0, 15), match='Leave me alone.'>\n",
      "<re.Match object; span=(0, 27), match=\"He shouldn't be left alone,\">\n",
      "<re.Match object; span=(0, 40), match='He is now leaving the two of them alone.'>\n",
      "-\n",
      "bad forms\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "positive_examples = [\"Leave me alone.\", \"He shouldn't be left alone, not yet.\", \"He is now leaving the two of them alone.\"]\n",
    "negative_examples = [\"huh\", \"Alone, I left my home.\", \"I left home to go fish abalone.\"]\n",
    "\n",
    "#your code here\n",
    "# regex = r\"\"\n",
    "\n",
    "print(\"good forms\")\n",
    "for form in positive_examples:\n",
    "    print(re.match(regex,form))\n",
    "\n",
    "print(\"-\")\n",
    "print(\"bad forms\")\n",
    "for form in negative_examples:\n",
    "    print(re.match(regex,form))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for testing is below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "pattern = re.compile(regex)\n",
    "\n",
    "for example in positive_examples:\n",
    "    assert pattern.match(example), example + \" not correctly included\"\n",
    "\n",
    "for example in negative_examples:\n",
    "    assert not pattern.match(example), example + \" not correctly excluded\"\n",
    "\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Narration and dialogue in Austen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1\n",
    "rubric={accuracy:3,efficiency:1}\n",
    "\n",
    "We have also made available to you via the web the complete works of Jane Austen annotated in [TEI format]( http://www.tei-c.org), which is a kind of XML. This text is from [Project Gutenberg](https://www.gutenberg.org), with automatic tagging provided using [GutenTag](http://www.projectgutentag.org); there are errors, but that's not your problem. Your first task is to create two very large strings, one corresponding to all the narrative in Austen's novels, the other corresponding to all the dialogue. You should load each novel by first concatenating (with +) the provided `url_path` with each filename from `filenames` below, and then using `urlopen` followed by  `BeautifulSoup`.\n",
    "\n",
    "All dialogue in each novel is tagged with the <said\\> tag. You can assume that any text within a paragraph in a chapter (that is, a NavigableString which is a child of a <p\\> tag which itself is the child of a <div type=\"chapter\"\\> tag) is narrative unless it is also under a <said\\> tag, at which point it is dialogue. You can assume that <said\\> tags appear only directly as children of <p\\> tags, and that no other tags do. That is, if D and N are strings correspond to dialogue and narration, they will be found in the XML in configurations such as:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "...\n",
    "<div type=\"chapter\">\n",
    "    (<p>\n",
    "        (<said> D </said>|N)+ \n",
    "    </p>)+\n",
    "</div\\>\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we are using regular expression notation here to express that there could be any number of Ns or D-containing <said\\> tags under any given <p\\>, and any number of <p\\>'s in a chapter. We are only interested in <p\\>'s inside chapters, not those in the front and end matter (e.g. the preface), so you do need to check for this. \n",
    "\n",
    "After you have extracted a list of D's and a list of N's, you should create single strings for each of narration dialogue by delimiting these N/D's with newlines. Assign these strings to variables `all_narration` and `all_dialogue` to run the asserts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_path = \"https://garrettnicolai.github.io/Garrett-Nicolai/COLX521/Austen/\"\n",
    "filenames = [\"EmmabyJaneAusten158.xml\", \"MansfieldParkbyJaneAusten141.xml\", \n",
    "             \"NorthangerAbbeybyJaneAusten121.xml\",\"PersuasionbyJaneAusten105.xml\",\n",
    "             \"PrideandPrejudicebyJaneAusten42671.xml\", \"SenseandSensibilitybyJaneAusten21839.xml\"]\n",
    "#your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n>   This is a \n",
      "d>  <keyword>declarative</keyword>\n",
      "    declarative\n",
      "n>   sentence .\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import lxml\n",
    "from bs4.element import Tag, NavigableString\n",
    "\n",
    "example = \"\"\"\n",
    "<text type=\"example\">\n",
    "<sent n=\"1\" type=\"declarative\"> This is a <keyword>declarative</keyword> sentence .</sent>\n",
    "</text>\n",
    "\"\"\"\n",
    "\n",
    "#my code here\n",
    "soup = BeautifulSoup(example,\"lxml\")\n",
    "\n",
    "for node in soup.find_all(\"sent\"):\n",
    "    if node.parent.name == \"text\": # and \"type\" in node.parent.attrs and node.parent[\"type\"] == \"example\":        \n",
    "        for child in node.contents:\n",
    "            if type(child) == NavigableString: # isinstance(child, NavigableString):\n",
    "                print(\"n> \", child)\n",
    "            else:\n",
    "                print(\"d> \", child)\n",
    "                print(\"   \", child.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_path = \"http://www.cs.toronto.edu/~jbrooke/COLX521/Austen/\"\n",
    "filenames = [\"EmmabyJaneAusten158.xml\", \"MansfieldParkbyJaneAusten141.xml\", \n",
    "             \"NorthangerAbbeybyJaneAusten121.xml\",\"PersuasionbyJaneAusten105.xml\",\n",
    "             \"PrideandPrejudicebyJaneAusten42671.xml\", \"SenseandSensibilitybyJaneAusten21839.xml\"]\n",
    "\n",
    "#your code here\n",
    "narrative_p = []\n",
    "dialogue_p = []\n",
    "for filename in filenames:\n",
    "    # ...\n",
    "    \n",
    "all_narrative = \"\\n\".join(narrative_p)\n",
    "all_dialogue =  \"\\n\".join(dialogue_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "assert all_narrative[:50] == 'Mr. Weston was a native of Highbury , and born of '\n",
    "assert all_dialogue[:50] == '“ I suppose you have heard of the handsome letter '\n",
    "assert 1600000 < len(all_dialogue) < 1700000 \n",
    "assert 2400000 < len(all_narrative) < 2500000\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2\n",
    "rubric={accuracy:3,quality:1,reasoning:1}\n",
    "\n",
    "Now write a function which counts the number of times the English [perfect aspect](https://en.wikipedia.org/wiki/Perfect_(grammar) is in used in a text string. Examples of perfect aspect are:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "I have eaten lunch already.\n",
    "They had finished their work.\n",
    "She has beaten me by ten points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get full credit for identifying the perfect aspect, you must\n",
    "\n",
    "a) cover major forms of the auxiliary verb \"have\" \n",
    "\n",
    "b) cover regular past participles (i.e. ends with \"ed\") and at least 5 common irregular past particles (e.g. \"been\", \"eaten\", \"taken\")\n",
    "\n",
    "c) allow exactly one word to appear between the auxiliary and past participle (e.g. \"have just eaten\").\n",
    "\n",
    "You should test your function with test cases which vary with regards to a, b, and c, and at least one case with more than one instance of the past perfect. Note that you should NOT do any part-of-speech tagging to solve this problem, simple string matching is fine.\n",
    "\n",
    "Once you are satisfied with your function in isolation, run it over the narration and dialogue strings from Austen and for each print out the average number of occurrences of the past perfect per 1000 words for each of dialogue and narration (HINT: the answer for both should be between 1 and 10, if your past perfect counter is working correctly). We can count the number of words just by counting the number of spaces in the string, that code is provided for you. \n",
    "\n",
    "Finally, state which kind of text has more past perfect, and briefly explain the result in light of the functional difference between narration and dialogue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your function (with regex) here\n",
    "# your code here\n",
    "\n",
    "irregulars = [\"become\", ...]\n",
    "\n",
    "# perf_regex = re.compile(r\"regex for `have` \n",
    "#                    AND optional word(s) \n",
    "#                    AND (a word which ends with `ed`\" + \"|\".join(irregulars) + \")\")\n",
    "\n",
    "def get_perfect_count(text):\n",
    "    '''returns a count of the number of times the perfect aspect appears in the provided text string'''\n",
    "    count = 0\n",
    "    ...\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "# write some test cases\n",
    "# your code here\n",
    "\n",
    "# pos_cases = [\"\", ...]\n",
    "# neg_cases = [\"\", ...]\n",
    "\n",
    "# for test_case in pos_cases:\n",
    "#     assert get_perfect_count(test_case) == 1\n",
    "\n",
    "# for test_case in neg_cases:\n",
    "#     assert get_perfect_count(test_case) == 0\n",
    "\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "Past Perfect per 1000 words, narrative:\n",
      "6.969497679285443\n",
      "Past Perfect per 1000 words, dialogue\n",
      "5.287277261911752\n"
     ]
    }
   ],
   "source": [
    "# Calculate final past perfect counts for Jane Austen novels, word counts provided\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Links (Optional)\n",
    "rubric={accuracy:1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access the [MDS-CL website](https://masterdatascience.ubc.ca/programs/computational-linguistics) using urlopen and automatically collect a set of all the internal links on the page, meaning those which point to the masterdatascience.ubc.ca either explicitly (because they start with https://masterdatascience.ubc.ca) or implicity (because they start with a single \"/\"); the URLs you find should not include any attach anchors (i.e. within-page links indicated by \"#\"). Also exclude any urls that involve CSS files. You can accomplish this task however you like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'/employers/post-job', '/why-data-science/success-stories', '/why-ubc/people/faculty/miikka-silfverberg-assistant-professor-mds-computational-linguistics', '/why-ubc/people/faculty/joel-ostblom-postdoctoral-research-and-teaching-fellow-mds-vancouver', '/contact-us/sign-updates', '/why-ubc/people/faculty/mike-gelbart-co-director-and-assistant-professor-teaching-mds-vancouver', '/employers', '/admissions/apply-now', '/admissions', '/why-ubc/events', '/why-data-science/student-success-stories/mds-spotlight-meet-celine-liu-mds-computational', '/why-ubc/industry-partners', '/why-ubc/students-and-alumni', '/why-ubc/people/faculty/varada-kolhatkar-assistant-professor-teaching-mds-vancouver', '/programs/okanagan', '/why-ubc/career-services', 'https://masterdatascience.ubc.ca/contact-us/sign-updates', '/why-data-science/alumni-data-science-stories', '/admissions/frequently-asked-questions', '/admissions/prerequisites', '/why-ubc/people/faculty/arman-seyed-ahmadi-postdoctoral-research-and-teaching-fellow-mds-vancouver', '/why-ubc/people', '/why-ubc/people/faculty/garrett-nicolai-assistant-professor-teaching-mds-computational-linguistics', '/admissions/tuition-and-financial-aid', '/admissions/international-students', '/employers/contact', '/contact-us/privacy-policy', '/employers/host-talk', '/why-data-science', 'https://masterdatascience.ubc.ca/programs/computational-linguistics', '/why-ubc/people/faculty/tiffany-timbers-co-director-and-assistant-professor-teaching-mds-vancouver', '/contact-us', '/why-data-science/data-science-in-action', '/employers/capstone-project', '/why-ubc/our-campuses', '/programs/computational-linguistics', '/admissions/how-apply', '/why-ubc/events/mds-computational-linguistics-student-alumni-panel-october-2021', '/why-ubc/people/faculty/muhammad-abdul-mageed-assistant-professor-mds-computational-linguistics', '/programs', '/why-ubc', '/why-ubc/people/faculty/alexi-rodriguez-arelis-postdoctoral-research-and-teaching-fellow-mds', '/sites/default/files/favicon.ico', '/programs/vancouver'}\n"
     ]
    }
   ],
   "source": [
    "internal_links = set()\n",
    "\n",
    "# your code here\n",
    "\n",
    "print(internal_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "assert '/admissions/frequently-asked-questions' in internal_links\n",
    "assert 'http://www.ubc.ca' not in internal_links\n",
    "assert 'https://masterdatascience.ubc.ca/sites/default/files/css/css_Q7R7Blo9EYqLDI5rIlO_T3uTFBjIXjLpcqMHjTvVdmg.css' not in internal_links\n",
    "print(\"Success!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "20bf69066c0dd38d51965b69d5e1b6e387082e3198ba56e97997ac55f4e50ad0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
