{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COLX 561 Lab Assignment 4: Discourse (Cheat sheet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment objectives\n",
    "\n",
    "In this assignment you will:\n",
    "- Manually analyze a short passage using the RST and Centering Theory frameworks\n",
    "- Show that texts in the Brown corpus have lexical coherence that can be identified using Word2Vec embeddings \n",
    "- Build a rule-based anaphor resolution system in the context of an existing annotated corpus (WikiCoref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "\n",
    "Run the code below to access relevant modules (you can add to this as needed):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#provided code\n",
    "import nltk\n",
    "import os\n",
    "import re\n",
    "import gensim\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "from nltk.corpus import brown\n",
    "from nltk import pos_tag\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.data import find\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tidy submission\n",
    "\n",
    "rubric={mechanics:1}\n",
    "\n",
    "To get the marks for tidy submission:\n",
    "\n",
    "- Submit the assignment by filling in this jupyter notebook with your answers embedded\n",
    "- Be sure to follow the [general lab instructions](https://ubc-mds.github.io/resources_pages/general_lab_instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Discourse analysis\n",
    "\n",
    "This exercise involves doing discourse analysis for the following 5 sentences:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. I saw my brother yesterday.\n",
    "2. I don't see him very often.\n",
    "3. He lives in Europe.\n",
    "4. My sister can afford to visit him regularly.\n",
    "5. I can't, though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1\n",
    "rubric={raw:3}\n",
    "\n",
    "Provide a reasonable RST parse for these sentences. For each relation, provide the relation name, the two spans involved (in order), and which of the two is the nucleus (if any). For example:\n",
    "\n",
    "```\n",
    "Condition 1-2 3 0\n",
    "``` \n",
    "\n",
    "which means there is a *condition* relationship between sentences 1-2 and sentence 3, and the nucleus is the first (ie, 0th) of the two spans. There is more than one reasonable interpretation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "- Background\n",
    "- Cause \n",
    "- Elaboration \n",
    "- Contrast "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2\n",
    "rubric={raw:3}\n",
    "\n",
    "Provide a centering algorithm analysis of these sentences. For each sentence, provide the $C_f$, $C_b$, and $C_p$, and the type of transition from the previous sentence, if appropriate. For example:\n",
    "\n",
    "4. $C_f$ = {Ted, Bill}, $C_b$ = Bill, $C_p$ = Ted, Retain"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "1. $C_f$ = ... , None\n",
    "2. $C_f$ = ... , Continue\n",
    "3. $C_f$ = ... , Smooth shift\n",
    "4. $C_f$ = ... , Retain\n",
    "5. $C_f$ = ... , Retain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Lexical coherence (Optional)\n",
    "\n",
    "rubric={accuracy:1}\n",
    "\n",
    "In this exercise you will be checking the lexical coherence of adjacent sentences in the Brown corpus, comparing coherence within a text and across text boundaries.\n",
    "\n",
    "Run the code below which creates a list of sentences from the first 50 texts of the Brown corpus and a list of the boundaries between them, and loads the built-in word2vec model included in `nltk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package word2vec_sample to\n",
      "[nltk_data]     /Users/jungyeul/nltk_data...\n",
      "[nltk_data]   Package word2vec_sample is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('word2vec_sample')\n",
    "\n",
    "# provided code\n",
    "doc_count = 0\n",
    "sents = []\n",
    "doc_boundaries = []\n",
    "\n",
    "for fileid in brown.fileids():\n",
    "    for sent in brown.sents(fileid):\n",
    "        sents.append(sent)\n",
    "    doc_boundaries.append(len(sents)) #This will establish the \"breakpoints\" between sentences\n",
    "    doc_count += 1\n",
    "    if doc_count == 50: #We're only interested in the first 50 documents\n",
    "        break\n",
    "\n",
    "doc_boundaries.pop(-1) # don't need the last boundary\n",
    "\n",
    "word2vec_sample = str(find('models/word2vec_sample/pruned.word2vec.txt'))\n",
    "word2vec_model = gensim.models.KeyedVectors.load_word2vec_format(word2vec_sample, binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task is to finish the `get_cosine_similarities()` function which creates an array consisting of the cosine similarities of the sums of the embeddings for the words in the $k$ sentences on either side of each sentence boundary in the corpus. You should not calculate this cosine similarity when you are less than $k$ from the edge; the code to insert placeholders (-1) for these is provided to you. Make sure you do this in an appropriately modular and efficient way."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The =   `[0.2, 0.3, 0.4]`\n",
    "* black = `[-0.1, 0.7, 1.5]`\n",
    "* cat =   `[0.5,-0.3, -0.4]`  \n",
    "\n",
    "The function will return `[0.6, 0.7, 1.5]` (`= [0.2-0.1+0.5, 0.3+0.7-0.3, 0.4+1.5-0.4]` by `np.sum(vectors, axis=0)`), which is a sentence represention for *The black cat*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector_sum(sents, word_vectors):\n",
    "    '''gets a sum of the word_vectors which represents the words in sents\n",
    "       sents: a list of sentences of length 'k'\n",
    "       Hint: passing a list of words to word_vectors will return a list of word vectors corresponding to the words.\n",
    "       Return value: a single vector that is the sum of the vectors for all the words in sents.\n",
    "       ie: The = [0.2, 0.3, 0.4], black = [-0.1, 0.7, 1.5], cat = [0.5,-0.3, -0.4].  Then \"The black cat\"\n",
    "       will give [[0.2, 0.3, 0.4], [-0.1, 0.7, 1.5], [0.5,-0.3,-0.4]], and the function will return\n",
    "       [0.6, 0.7, 1.5] (ie, [0.2 - 0.1 + 0.5, 0.3-0.3+0.7, 0.4+1.5-0.4])  This function will then sum\n",
    "       up those vectors along a single axis, giving a single vector that is the sum of the vectors of each word\n",
    "       in the sentence.\n",
    "    '''\n",
    "# my code here\n",
    "    words = []\n",
    "    for sent in sents:\n",
    "        words.extend([word.lower() for word in sent if word.lower() in word_vectors])\n",
    "    return np.sum(word_vectors[words], axis=0)\n",
    "# my code here\n",
    "\n",
    "from scipy.spatial.distance import cosine # similarity = 1 - cosine distance; \n",
    "\n",
    "def get_cosine_similarities(sents, word_vectors,k):\n",
    "    ''' returns an array of similarities of len(sents), corresponding to the cosine of the\n",
    "    vectors produced by summing the embeddings of words in the k sentences of either side of \n",
    "    each sentence boundary, with the first and last k similarities set to -1\n",
    "    \n",
    "    For each sentence in the range from k to len(sents) - k, you should append the cosine between\n",
    "    the sum of k sentences before the current sentence (using get_vector_sum), and the k sentences after (again, using get_vector_sum) \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    cosine_similarities = [-1]*k #Set first k similarities to -1\n",
    "    #your code here\n",
    "\n",
    "    #your code here\n",
    "    for i in range(k):\n",
    "        cosine_similarities.append(-1) #Set last k similarities to -1\n",
    "    \n",
    "    return np.array(cosine_similarities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below compares the cosine similarities of sentence boundaries which are also document boundaries to cosine similarities involving only sentences within a text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarities = get_cosine_similarities(sents,word2vec_model,3)\n",
    "print(len(cosine_similarities))\n",
    "doc_boundary_mean = np.mean(cosine_similarities[doc_boundaries])\n",
    "doc_boundaries_window = set()\n",
    "\n",
    "for boundary in [0,len(cosine_similarities)] + doc_boundaries:\n",
    "    doc_boundaries_window.update(range(boundary -3, boundary + 3))\n",
    "non_doc_boundaries = list(set(range(len(cosine_similarities))) - doc_boundaries_window)\n",
    "non_doc_boundary_mean = np.mean(cosine_similarities[non_doc_boundaries])\n",
    "\n",
    "print(doc_boundary_mean)\n",
    "print(non_doc_boundary_mean)\n",
    "\n",
    "assert(doc_boundary_mean < 0.8)\n",
    "assert(len(cosine_similarities) == 5238)\n",
    "assert(non_doc_boundary_mean - doc_boundary_mean > 0.05)\n",
    "print(\"Success!\")       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Anaphor resolution for pronouns\n",
    "\n",
    "In this exercise, we will make use of the WikiCoref corpus, which can be downloaded [here](http://rali.iro.umontreal.ca/rali/sites/default/files/resources/wikicoref/WikiCoref.tar.gz). Do not include it with your submission, instead you should put the path to the `Annotation` directory of the unzipped corpus here, and we will change the path if we need test your code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ghaddar, A., & Langlais, P. (2016). **WikiCoref: An English Coreference-annotated Corpus of Wikipedia Articles**. In *Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC’16)*, 136–142. https://aclanthology.org/L16-1021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Susan dropped [the plate]$_1$. [It]$_1$ shattered loudly.***\n",
    "\n",
    "- ***It* is an anaphor**\n",
    "- ***the plate* and *It* have the same referent (co-reference)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#provided code\n",
    "wikicoref_path = \"... Lab4/WikiCoref/Annotation/\" # modify this path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Wikicoref corpus contains Wikipedia texts with annotations of coreference relationships among entity mentions in those texts. The `Annotation` directory contains a series of subdirectories with each one corresponding to a Wikipedia entry. There are two files that we will access for each entry. The first is a text file which contains the text, one token on each line, with a single blank line. Below is a provided function `get_text_with_boundaries()` which (assuming you have the correct `wikicoref_path`) will build two data structures you will need: a text consisting of a list of tokens, and a set which has the indicies of the sentence boundaries. You don't need to modify this code. Note that the text must be a list of tokens (and not a list of sentences) so that mentions can be properly identified using the information you will collect in **3.1**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Canada % ls -R`**\n",
    "\n",
    "```\n",
    "Basedata\t\tCanada.txt(*)\t\tMarkables\t\tStyles\n",
    "Canada.mmax\t\tCustomizations\t\tSchemes\t\t\tcommon_paths.xml\n",
    "\n",
    "./Basedata:\n",
    "Canada_words.xml\twords.dtd\n",
    "\n",
    "./Customizations:\n",
    "coref_customization.xml\t\tsentence_customization.xml\n",
    "\n",
    "./Markables:\n",
    "Canada_coref_level.xml(*)\t\t\tCanada_coref_level_OntoNotesScheme.xml\ttest\n",
    "Canada_coref_level.xml.bak\t\tCanada_sentence_level.xml\n",
    "Canada_coref_level_ACEScheme.xml\tmarkables.dtd\n",
    "\n",
    "./Schemes:\n",
    "coref_scheme.xml\tsentence_scheme.xml\n",
    "\n",
    "./Styles:\n",
    "default_style.xsl\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Barack_Obama % ls -R**\n",
    "```\n",
    "Barack Obama.mmax\tBasedata\t\tMarkables\t\tStyles\n",
    "Barack Obama.txt\tCustomizations\t\tSchemes\t\t\tcommon_paths.xml\n",
    "\n",
    "./Basedata:\n",
    "Barack Obama_words.xml\twords.dtd\n",
    "\n",
    "./Customizations:\n",
    "coref_customization.xml\t\tsentence_customization.xml\n",
    "\n",
    "./Markables:\n",
    "Barack Obama_coref_level.xml\t\t\tBarack Obama_coref_level_OntoNotesScheme.xml\ttest\n",
    "Barack Obama_coref_level.xml.bak\t\tBarack Obama_sentence_level.xml\n",
    "Barack Obama_coref_level_ACEScheme.xml\t\tmarkables.dtd\n",
    "\n",
    "./Schemes:\n",
    "coref_scheme.xml\tsentence_scheme.xml\n",
    "\n",
    "./Styles:\n",
    "default_style.xsl\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Barack_Obama/Barack Obama_coref_level.xml`\n",
    "\n",
    "\n",
    "- `Barack_Obama`    (with `_` )\n",
    "- `Barack Obama_coref_level.xml`  (without `_` )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#provided code\n",
    "def get_text_with_boundaries(entry):\n",
    "    '''given an Wikicoref entry name, opens the corresponding text file in the Wikicoref corpus and \n",
    "    coverts it into a list of tokens and a set which has indicies of the boundaries between sentences'''\n",
    "    text_filename = entry.replace(\"_\",\" \") + \".txt\"\n",
    "    sentence_boundaries = set()\n",
    "    text = []\n",
    "    with open(wikicoref_path + \"/\" + entry + \"/\" + text_filename,encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                text.append(line)\n",
    "            else:\n",
    "                sentence_boundaries.add(len(text) - 1)\n",
    "    return text,sentence_boundaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `get_text_with_boundaries(\"word\")[0]` = a list of tokens\n",
    "- `get_text_with_boundaries(\"word\")[1]` = a set of sentence boundary position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Canada', 'is', 'a', 'North', 'American', 'country', 'consisting', 'of', 'ten', 'provinces', 'and', 'three', 'territories', '.', 'Located', 'in', 'the', 'northern', 'part', 'of', 'the', 'continent', ',', 'it', 'extends', 'from', 'the', 'Atlantic', 'to', 'the', 'Pacific', 'and', 'northward', 'into', 'the', 'Arctic', 'Ocean', '.', 'Canada', 'is']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(get_text_with_boundaries(\"Canada\")[0][:40])\n",
    "37 in get_text_with_boundaries(\"Canada\")[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The other function will load a list of objects which have information about entity mentions from an XML file (`*entry name*_coref_level.xml`) found in the `Markables` directory inside the folder for the entry.  You also don't need to modify this code.  I encourage you to take a look at what is returned by this function, as it will help you with the later exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <markable id=\"markable_318\" span=\"word_1..word_1\" coref_class=\"set_399\" topic=\"http://rdf.freebase.com/ns/m.0d060g\" coreftype=\"ident\" mentiontype=\"ne\"  mmax_level=\"coref\" />\n",
    "# <markable id=\"markable_319\" span=\"word_3..word_13\" coref_class=\"set_399\" topic=\"http://rdf.freebase.com/ns/m.0d060g\" coreftype=\"cop\" mentiontype=\"np\"  mmax_level=\"coref\" />\n",
    "# <markable id=\"markable_538\" span=\"word_4..word_5\" coref_class=\"set_3\" topic=\"http://rdf.freebase.com/ns/m.059g4\" coreftype=\"ident\" mentiontype=\"ne\"  mmax_level=\"coref\" />\n",
    "# <markable id=\"markable_555\" span=\"word_9..word_10\" coref_class=\"set_226\" topic=\"nan\" coreftype=\"ident\" mentiontype=\"np\"  mmax_level=\"coref\" />\n",
    "# <markable id=\"markable_552\" span=\"word_9..word_13\" coref_class=\"set_27\" topic=\"nan\" coreftype=\"ident\" mentiontype=\"np\"  mmax_level=\"coref\" />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mention_info(entry):\n",
    "    '''Creates a list of mention_info objects for the Wikipedia entry from the corpus. Here, a \n",
    "    mention_info object corresponds to a beautiful soup node of a markable tag in the Wikicoref xml'''\n",
    "    mention_info_list = []\n",
    "    with open(wikicoref_path + \"/\" + entry + \"/Markables/\" +entry.replace(\"_\", \" \") +\"_coref_level.xml\",encoding=\"utf-8\") as f:\n",
    "        soup = BeautifulSoup(f,\"lxml\")\n",
    "        for markable in soup.find_all(\"markable\"):\n",
    "            mention_info_list.append(markable)\n",
    "    return mention_info_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<markable coref_class=\"set_399\" coreftype=\"ident\" id=\"markable_318\" mentiontype=\"ne\" mmax_level=\"coref\" span=\"word_1..word_1\" topic=\"http://rdf.freebase.com/ns/m.0d060g\"></markable>,\n",
       " <markable coref_class=\"set_399\" coreftype=\"cop\" id=\"markable_319\" mentiontype=\"np\" mmax_level=\"coref\" span=\"word_3..word_13\" topic=\"http://rdf.freebase.com/ns/m.0d060g\"></markable>,\n",
       " <markable coref_class=\"set_3\" coreftype=\"ident\" id=\"markable_538\" mentiontype=\"ne\" mmax_level=\"coref\" span=\"word_4..word_5\" topic=\"http://rdf.freebase.com/ns/m.059g4\"></markable>,\n",
       " <markable coref_class=\"set_226\" coreftype=\"ident\" id=\"markable_555\" mentiontype=\"np\" mmax_level=\"coref\" span=\"word_9..word_10\" topic=\"nan\"></markable>,\n",
       " <markable coref_class=\"set_27\" coreftype=\"ident\" id=\"markable_552\" mentiontype=\"np\" mmax_level=\"coref\" span=\"word_9..word_13\" topic=\"nan\"></markable>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_mention_info(\"Canada\")[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "assert len(get_mention_info(\"Canada\")) == 1079\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1\n",
    "\n",
    "rubric={accuracy:2}\n",
    "\n",
    "Next, you're going to complete a function which will allow you to grab the actual text corresponding to the mention. `get_mention_indices()` should take one of the `mention_info` objects created above and pull out a 2-tuple of indices (Hint: remember \"match\" and \"group\" for RegExes from 521?); The provided function `get_mention()` does the rest, getting the text associated with those tuples. You will need to use `get_mention()` extensively for the rest of this exercise.\n",
    "\n",
    "The one slightly tricky part of this problem is that this corpus annotation uses a different indexing philosophy than Python does! You will want to figure this out first, and convert the one in the annotation to the one that Python uses.\n",
    "\n",
    "The other functions provided below also deal with indicies but can be ignored for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We need to store the following attributes of each `markable` XML tag: `span` (`get_mention_indices()`), `coref_class`, and `mentiontype`.**\n",
    "\n",
    "```\n",
    "<markable \n",
    "    coref_class=\"set_399\"        \n",
    "    coreftype=\"cop\" \n",
    "    id=\"markable_319\" \n",
    "    mentiontype=\"np\"             \n",
    "    mmax_level=\"coref\" \n",
    "    span=\"word_3..word_13\"       <--- get_mention_indices()\n",
    "    topic=\"http://rdf.freebase.com/ns/m.0d060g\">\n",
    "</markable>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "span_re = re.compile(r\"word_(\\d+)\\.\\.word_(\\d+)\")\n",
    "#The items returned from \"get_mention_info\" contains a string \"word_X..word_Y\", where X is the index\n",
    "#before the span, and Y is the index after the span.\n",
    "\n",
    "\n",
    "def get_mention_indices(mention_info):\n",
    "    '''takes a mention_info object created by the get_mention_info function and \n",
    "    returns a tuple of integers corresponding to the span of the mention in the text'''\n",
    "    # your code here\n",
    "    # `mention_info[\"span\"]` will return `word_3..word_13` (see above);\n",
    "    # you extract numbers from word_3..word_13 using group(1) and group(2)\n",
    "    # and return (3-1, 13);\n",
    "    # note that you should return int, not str. \n",
    "    # your code here\n",
    "    \n",
    "def get_mention(mention_info,text):\n",
    "    '''get a list of tokens from text corresponding to the mention from mention_info'''\n",
    "    start,end = get_mention_indices(mention_info)\n",
    "    return text[start:end]\n",
    "\n",
    "### used for 3.5\n",
    "def get_mentions_ind_for_same_sentence(index, mention_list, sentence_boundaries):\n",
    "    '''given a starting index in mention_list, this returns the index of the mention in mention_list which\n",
    "    is the first mention in the same sentence as index, based on the provided set of sentence_boundaries'''\n",
    "    mention_start, mention_end = get_mention_indices(mention_list[index])\n",
    "    i = mention_start\n",
    "    while i >=0 and i not in sentence_boundaries:\n",
    "        i -=1\n",
    "    j = index - 1\n",
    "    while j >=0 and get_mention_indices(mention_list[j])[0] >= i:\n",
    "        j -= 1\n",
    "    return j + 1\n",
    "\n",
    "#### Functions below are not needed but good for checking what you're doing (print out sentences with mentions)\n",
    "def get_mention_sentence_indices(mention_info,sentence_boundaries):\n",
    "    '''takes a mention info object created by the get_mention_info function and the list of sentence boundaries in the\n",
    "    corresponding text, and returns the indicies of the sentece which contain that mention'''\n",
    "    mention_start, mention_end = get_mention_indices(mention_info)\n",
    "    sent_start = mention_start\n",
    "    while sent_start - 1 not in sentence_boundaries and sent_start > 0:\n",
    "        sent_start -= 1\n",
    "    sent_end = mention_end\n",
    "    while sent_end not in sentence_boundaries and sent_end < len(text):\n",
    "        sent_end += 1\n",
    "    return (sent_start,sent_end)\n",
    "\n",
    "def get_mention_sentence(mention_info,sentence_boundaries,text):\n",
    "    '''get a list of tokens from text corresponding to sentence containing the mention from \n",
    "    mention_info'''    \n",
    "    start,end = get_mention_sentence_indices(mention_info,sentence_boundaries)\n",
    "    return text[start:end]                                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 13)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# <markable id=\"markable_552\" span=\"word_9..word_13\" ...\n",
    "get_mention_indices(get_mention_info(\"Canada\")[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<markable coref_class=\"set_27\" coreftype=\"ident\" id=\"markable_552\" mentiontype=\"np\" mmax_level=\"coref\" span=\"word_9..word_13\" topic=\"nan\"></markable>\n",
      "['Canada', 'is', 'a', 'North', 'American', 'country', 'consisting', 'of', 'ten', 'provinces', 'and', 'three', 'territories', '.', 'Located', 'in', 'the', 'northern', 'part', 'of', 'the', 'continent', ',', 'it', 'extends', 'from', 'the', 'Atlantic', 'to', 'the']\n",
      "['ten', 'provinces', 'and', 'three', 'territories']\n"
     ]
    }
   ],
   "source": [
    "print(get_mention_info(\"Canada\")[4])\n",
    "print(get_text_with_boundaries(\"Canada\")[0][:30])\n",
    "print(get_mention(get_mention_info(\"Canada\")[4], get_text_with_boundaries(\"Canada\")[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2\n",
    "\n",
    "rubric={accuracy:3}\n",
    "\n",
    "Next, use the `get_mention()` function from above to iterate over all the mentions in the corpus and use the information in the `mentiontype` field to collect a set of all the pronouns (\"pro\").  HINT: the mention will have a key: `mentiontype`. Print out this set (you should lowercase your pronouns, so that you don't end up with lowercased and uppercased pronouns in the set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "<markable \n",
    "    coref_class=\"set_399\" \n",
    "    coreftype=\"ident\" \n",
    "    id=\"markable_594\" \n",
    "    mentiontype=\"pro\"             <---\n",
    "    mmax_level=\"coref\" \n",
    "    span=\"word_24..word_24\" \n",
    "    topic=\"http://rdf.freebase.com/ns/m.0d060g\">\n",
    "</markable>\n",
    "```\n",
    "\n",
    "* using `get_mention_info()`, find `mentiontype == \"pro\"` and add it to `pronouns`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'his', 'him', 'itself', 'we', 'i', 'them', 'her', 'those', 'she', 'herself', 'myself', 'me', 'they', 'its', 'my', 'their', 'our', 'you', 'these', 'he', 'ourselves', 'it', 'himself', 'your', 'themselves', 'this'}\n"
     ]
    }
   ],
   "source": [
    "pronouns = set()\n",
    "for entry in os.listdir(wikicoref_path):\n",
    "    if \".ini\" in entry: #ignore .ini entries\n",
    "        continue\n",
    "    #Your code here\n",
    "    # 1. get_mention_info(entry) will return `mention_info_list`\n",
    "    # 2. get_text_with_boundaries(entry)` will return `text` and `sentence_boundaries`\n",
    "    # 3. you iterate `mention_info_list` to find `mention_info[\"mentiontype\"] == \"pro\"\n",
    "    # 4. if you find it: using `get_mention(mention_info,text)` to add in `pronouns` (don't forget `lower()` for your pronouns`)\n",
    "\n",
    "    #Your code here            \n",
    "print(pronouns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this, we create a new object called `pronoun_features` which has, for each *3rd-person* pronoun, a feature dictionary with information about the number, personhood, and gender of the pronoun.  Remember that the *3rd-person* refers to individuals that are not being addressed directly (ie, \"he\", \"she\", \"they\", \"her\", etc.) Note that personhood $\\neq$ (grammatical) person, e.g. *3rd-person*.  Instead, personhood is whether the pronoun refers to a person. You should remove first and second pronouns (such as *me* and *you*). Here's an example with a suggested schema you could use to use for this:\n",
    "\n",
    "```\n",
    "{\"she\": {\"PLUR\": False,\n",
    "         \"PERS\": True,\n",
    "         \"MALE\": False}}\n",
    "```\n",
    "\n",
    "Note that if a pronoun isn't specified for one of these attibutes (e.g. *they* isn't specified for gender or personhood in English), the feature (e.g. \"MALE\") should not be included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Provided code:\n",
    "pronoun_features = {'itself':{\"PERS\":False,\"PLUR\":False},\n",
    "                'they':{\"PLUR\":True}, 'them':{\"PLUR\":True}, \n",
    "                'those':{\"PERS\":False,\"PLUR\":True}, \n",
    "                'their':{\"PLUR\":True}, \n",
    "                'themselves':{\"PLUR\":True}, \n",
    "                'this':{\"PLUR\":False,\"PERS\":False}, \n",
    "                'his':{\"PLUR\":False,\"PERS\":True,\"MALE\":True}, \n",
    "                'he':{\"PLUR\":False,\"PERS\":True,\"MALE\":True}, \n",
    "                'herself':{\"PLUR\":False,\"PERS\":True,\"MALE\":False}, \n",
    "                'she':{\"PLUR\":False,\"PERS\":True,\"MALE\":False}, \n",
    "                'its':{\"PLUR\":False,\"PERS\":False,\"MALE\":True}, \n",
    "                'him':{\"PLUR\":False,\"PERS\":True,\"MALE\":True}, \n",
    "                'her':{\"PLUR\":False,\"PERS\":True,\"MALE\":False}, \n",
    "                'himself':{\"PLUR\":False,\"PERS\":True,\"MALE\":True}, \n",
    "                'it':{\"PLUR\":False,\"PERS\":False}, \n",
    "                'these':{\"PLUR\":True,\"PERS\":False},\n",
    "                'them':{\"PLUR\":True}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can compare these feature dictionaries for compatibility using the provided `compatible()` function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#provided code\n",
    "def compatible(mention1,mention2):\n",
    "    '''\n",
    "       This function checks that two mentions match in all marked pronoun features\n",
    "    '''\n",
    "    for feature in mention1:\n",
    "        if feature in mention2 and mention1[feature] != mention2[feature]:\n",
    "            return False\n",
    "    for feature in mention2:\n",
    "        if feature in mention1 and mention1[feature] != mention2[feature]:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "assert \"me\" not in pronoun_features\n",
    "assert \"you\" not in pronoun_features\n",
    "assert compatible(pronoun_features[\"this\"],pronoun_features[\"it\"])\n",
    "assert not compatible(pronoun_features[\"their\"],pronoun_features[\"it\"])\n",
    "assert compatible(pronoun_features[\"she\"],pronoun_features[\"her\"])\n",
    "assert not compatible(pronoun_features[\"she\"],pronoun_features[\"himself\"])\n",
    "assert not compatible(pronoun_features[\"her\"],pronoun_features[\"its\"])\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3\n",
    "\n",
    "rubric={accuracy:3,quality:1}\n",
    "\n",
    "Next you will build a basic coreference system and test it out. Complete the `test_anaphor_resolution_system` function below. Your algorithm should do the following:\n",
    "\n",
    "1. Iterate over all the wikipedia entries and, for each entry, iterate over the mentions using indicies (This code is provided for you). \n",
    "\n",
    "2. When you find an anaphor (pronoun) that is in your `pronoun_feature` dict from **3.2** (you should add 1 to `total` at this point), you will attempt to find its antecedent by iterating though past mentions using a second index which you must get from the `search_iterator` (by default, this just iterates backwards, however you will upgrade this function in **3.4**)\n",
    "\n",
    "3. When the past mention is a non-anaphoric mention (ie, not a pronoun), you will extract its features by passing its features by passing the result of `get_mention` function from **3.1** to the `get_mention_features` function (currently just returns an empty dictionary but you will upgrade this in **3.5**!) and check to see if your current pronoun is compatible with it, using the `compatible` function given above. If it is not compatible, the search should continue.\n",
    "\n",
    "4. If it is, then your system will guess that antecedent. You can check to see if you are correct by seeing if the pronoun and potential antecedent have the same \"coref_class\", if so, you should add 1 to `correct`.\n",
    "\n",
    "5. Regardless of whether you are correct or not, once you have guessed an antecedent for the anaphor, you should stop looking for an antecedent and continue looking for the next anaphor (back to step 1).\n",
    "\n",
    "6. When you have finished trying to find antecedents for all anaphors in all the entries, return your accuracy (this code is provided)\n",
    "\n",
    "As suggested above, you MUST use the two functions given below in your implementation. They are not doing much right now (ignoring their arguments, in fact), but you will improve them later.\n",
    "\n",
    "Run the provided test code to see how well your basic system is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<markable coref_class=\"set_399\" coreftype=\"ident\" id=\"markable_318\" mentiontype=\"ne\" mmax_level=\"coref\" span=\"word_1..word_1\" topic=\"http://rdf.freebase.com/ns/m.0d060g\"></markable>\n",
      "['Canada']\n",
      "-\n",
      "<markable coref_class=\"set_399\" coreftype=\"cop\" id=\"markable_319\" mentiontype=\"np\" mmax_level=\"coref\" span=\"word_3..word_13\" topic=\"http://rdf.freebase.com/ns/m.0d060g\"></markable>\n",
      "['a', 'North', 'American', 'country', 'consisting', 'of', 'ten', 'provinces', 'and', 'three', 'territories']\n",
      "-\n",
      "<markable coref_class=\"set_399\" coreftype=\"ident\" id=\"markable_594\" mentiontype=\"pro\" mmax_level=\"coref\" span=\"word_24..word_24\" topic=\"http://rdf.freebase.com/ns/m.0d060g\"></markable>\n",
      "['it']\n"
     ]
    }
   ],
   "source": [
    "print(get_mention_info(\"Canada\")[0])\n",
    "print(get_mention(get_mention_info(\"Canada\")[0], get_text_with_boundaries(\"Canada\")[0]))\n",
    "print(\"-\")\n",
    "\n",
    "print(get_mention_info(\"Canada\")[1])\n",
    "print(get_mention(get_mention_info(\"Canada\")[1], get_text_with_boundaries(\"Canada\")[0]))\n",
    "\n",
    "print(\"-\")\n",
    "print(get_mention_info(\"Canada\")[6])\n",
    "print(get_mention(get_mention_info(\"Canada\")[6], get_text_with_boundaries(\"Canada\")[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_iterator(anaphor_index, mention_info_list,sentence_boundaries):\n",
    "    '''a generator function which just ignores most of its arguements and just provides indices\n",
    "    backwards order starting with the index before the provided anaphor_index'''\n",
    "    for i in range(anaphor_index - 1,-1,-1):\n",
    "        yield i\n",
    "\n",
    "def get_mention_features(mention):\n",
    "    '''just returns an empty dictionary, which means the mention has no known features and so\n",
    "    will be compatible with everything'''\n",
    "    return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_anaphor_resolution_system(wikicoref_path):\n",
    "    '''interates through all the mentions for all the wikipedia entries in wikipedia path and attempts to assign an antecedant\n",
    "    to each. Returns an accuracy score based on how many antecedants are correctly assigned'''\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for entry in os.listdir(wikicoref_path):\n",
    "        if \".ini\" in entry:\n",
    "            continue\n",
    "        mention_info_list = get_mention_info(entry)\n",
    "        text, sentence_boundaries = get_text_with_boundaries(entry)\n",
    "        for i in range(len(mention_info_list)):\n",
    "            # your code here for step 2:\n",
    "            # in this snippet, you should check \n",
    "            # if the current mention (`mention_info_list[i]`)'s `mentiontype` is a pronoun in the pronoun list.  \n",
    "            # If it is (using `get_mention()` and lower()), you should get its features \n",
    "            #   from the `pronoun_features`` dictionary above.\n",
    "            #   and total += 1\n",
    "            \n",
    "            # your code here\n",
    "                    for j in search_iterator(i, mention_info_list,sentence_boundaries):\n",
    "                        # your code here:\n",
    "                        # in this snippet, you should check if the mention (`get_mention(mention_info_list[j],text)`) \n",
    "                        #       returned by the search iterator\n",
    "                        # If it is compatible with your current pronoun (from the for loop above)\n",
    "                        #       check that the coreference class of the pronoun is the same as this reference\n",
    "                        #       If it is, then increase the number of correctly predicted items. correct += 1\n",
    "                        #       and break\n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3922413793103448\n",
      "Success!\n"
     ]
    }
   ],
   "source": [
    "result = test_anaphor_resolution_system(wikicoref_path)\n",
    "print(result)\n",
    "assert 0.39 < result < 0.40\n",
    "print(\"Success!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4\n",
    "\n",
    "rubric={accuracy:2}\n",
    "\n",
    "The next piece of your anaphor resolution system will involve an enhancement to your backward searching process: instead of just stepping back mention-by-mention, you will start looking from the *beginning* of sentences rather than the end. This is a rough way of injecting information about grammatical saliency into your search for an antecedent (in English, at least, the subject often comes first, and has highest salience). A major piece of this has been done for you, in the form of the `get_mentions_ind_for_same_sentence()` function provided with the other mention functions in **3.1**. For the example below:\n",
    "\n",
    "***Ted* is happy. *He* is getting married to *Molly* who used to be married to *Fred*. *Her* bridesmaid is *Dolly* and *his* best man is *Ned*.**\n",
    "\n",
    "We have the mentions: *Ted*, *He*, *Molly*, *Fred*, *Her*, *Dolly*, *his*, and *Ned*. If we are looking for the antecedent of *his*, calling `get_mentions_ind_for_same_sentence()` with the index of mention *his* will return the index of *Her* (ie, the start of that sentence). Using that index as a starting point, we would check forward through that sentence until we hit *his*, and then move to the previous sentence by calling `get_mentions_ind_for_same_sentence()` on the mention before *Her*, namely *Fred*. That would get us started at the index for *He*, and then we iterate forward until we hit *Her*, at which point we call  `get_mentions_ind_for_same_sentence()` on *Ted*, return *Ted*'s index, then stop because we are already at index 0. Implement this logic as a generator function (**HINT**: your solution should have one `while` loop and then one `for` loop within it).\n",
    "\n",
    "So the process is: \n",
    "1. starting with \"his\" in the final sentence, find the first mention in the sentence, using `get_mentions_ind_for_same_sentence`.  \n",
    "2. Starting at that index, yield the indices for the words between that word and the anaphor in the sentence. \n",
    "3. Decrease the index to the word before the mention found in 1. \n",
    "4. Return to 1.  If your index is 0, you're done, because you are at the end of the sentence.\n",
    "\n",
    "For the example sentence, the indices will be [16 (Her),17,18,19,20,21,3 (He),4,5,6,7,8,9,10,11,12,13,14,15,0 (Ted),1,2] (You don't need the items in parentheses - those are just for clarification)  The logic behind this order is this: \"to disambiguate this anaphor, go to the start of this sentence, and check the compatibility of all words with the anaphor - if you find one that disambiguates it, good!  If not, go to the previous sentence, and do the same thing.  Keep doing this until you get to the start of the discourse\".\n",
    "\n",
    "There are two sets of tests below: one tests whether the algorithm is working properly, and the other calls `test_anaphor_resolution_system` again to see whether how much this new version of `search_iterator` has improved performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "```\n",
    "0*Ted* is happy. \n",
    "1*He* is getting married to 2*Molly* who used to be married to 3*Fred*. \n",
    "4*Her* bridesmaid is 5*Dolly* and 6*his* best man is 7*Ned*.\n",
    "```\n",
    "***\n",
    "\n",
    "previously, using `search_iterator()` with `anaphor_index` = 6 (*his*):\n",
    "```\n",
    "indicies == [5, 4, 3, 2, 1, 0]    \n",
    "```\n",
    "\n",
    "\n",
    "for now, using *new* `search_iterator()` with `anaphor_index` = 6 (*his*):\n",
    "```\n",
    "indicies == [4, 5, 1, 2, 3, 0]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_iterator(anaphor_index, mention_list, sentence_boundaries):\n",
    "    '''generator function which yields indices in mention_list based on the idea of moving backwards through the text starting\n",
    "    from end_index but forward through sentences as indicated by the set of sentence_boundaries'''\n",
    "    start_index = -1\n",
    "    end_index = anaphor_index\n",
    "    first = True\n",
    "    # your code here\n",
    "\n",
    "    # your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "mention_list = get_mention_info(\"Canada\")\n",
    "text,sentence_boundaries = get_text_with_boundaries(\"Canada\")\n",
    "indices = list([index for index in search_iterator(14, mention_list,sentence_boundaries)])\n",
    "assert indices == [10, 11, 12, 13, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5] #How many sentences are in this utterance?\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5275862068965518\n",
      "Success!\n"
     ]
    }
   ],
   "source": [
    "result = test_anaphor_resolution_system(wikicoref_path)\n",
    "print(result)\n",
    "assert 0.52 < result < 0.53\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5\n",
    "\n",
    "rubric={accuracy:3, quality:1}\n",
    "\n",
    "Finally, you will upgrade the `get_mention_features` function so that it guesses at least one of the three relevant features for *non-pronomial* mentions. Based on our pronoun list, there are clearly three options for this: plural (whether a mention is plural), person (whether the mention is a person), and gender (whether the mention is male or female). For example, if provided the mention ```[\"the\", \"boy\"]```, a fully-functional version of `get_mention_features` would return a dictionary ```{\"PLUR\":False,\"PERS\":True,\"MALE\":True}``` You can use any resources you like for this, including POS taggers, manually-created or off-the-shelf lexicons (remember that NLTK has a lexicon of male and female names!), WordNet, word2vec vectors, sklearn classifiers, etc. You can get up to 3 points of bonus for this question if you tackle multiple features or provide a particularly comprehensive solution for one of them, but you only have to cover one feature get the non-optional points. \n",
    "\n",
    "First, you must test your function *intrinsically* by showing your function is working for particular mentions. To do this, iterate over mentions (your code from **3.3** can be modified for this purpose). and print out the mention and the output of `get_mention_features`. Based on your own manual analysis, you should be getting at least 3/4 of cases *in both classes*, if not, try to improve your function. When you are satisfied with your performance, test *extrinsically* by using the new `get_mention_features` in the context of your coreference resolution system. It is okay if your extrinsic evaluation gives negative results, as long as your intrinsic evaluation shows you are doing pretty well (though it definitely should be possible to improve your overall results!). Note if this was a real world situation we'd probably want to segregate our intrinsic and extrinsic evaluations (make sure they aren't being done over the same mentions) since the former might involve overfitting on the specific mentions in this set, but we are not going to require you worry about this here (though you can if you like!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`[\"the\", \"boy\"] --> {\"PLUR\":False,\"PERS\":True,\"MALE\":True}`\n",
    "\n",
    "\n",
    "```\n",
    "pos_tag([\"the\", \"boy\"]) --> [\"DT\", \"NN\"]\n",
    "pos_tag([\"boys\"])       --> [\"NNS\"]\n",
    "```\n",
    "if one of pos tags in mention ends with `\"S\"`, then `\"PLUR\":True`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mention_features(mention):\n",
    "    '''returns a feature dictionary with PLUR either true or false depending on whether the corresponding mention \n",
    "    has a plural noun based on part of speech tagged'''\n",
    "    features = {}\n",
    "    #Your code here\n",
    "\n",
    "    #Your code here\n",
    "    return features\n",
    "\n",
    "def check_mention_features():\n",
    "    '''print out mentions and mention features for the first five non-pronomial mentions of each entry \n",
    "    in WikiCoref corpus'''\n",
    "    for entry in os.listdir(wikicoref_path):\n",
    "        if \".ini\" in entry:\n",
    "            continue\n",
    "        count = 0\n",
    "        mention_info_list = get_mention_info(entry)\n",
    "        text,sentence_boundaries = get_text_with_boundaries(entry)\n",
    "        for mention_info in mention_info_list:      \n",
    "            if mention_info[\"mentiontype\"] != \"pro\":\n",
    "                count += 1\n",
    "                mention = get_mention(mention_info,text)\n",
    "                print(mention)\n",
    "                print(get_mention_features(mention))\n",
    "                if count == 5:\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Siege', 'of', 'Chaves']\n",
      "{'PLUR': True}\n",
      "['the', 'French', 'siege', 'and', 'capture', 'of', 'Chaves', ',', 'Portugal', 'from', '10', 'to', '12', 'March', '1809', ',', 'and', 'the', 'subsequent', 'siege']\n",
      "{'PLUR': False}\n",
      "['Chaves']\n",
      "{'PLUR': True}\n",
      "['Portugal']\n",
      "{'PLUR': False}\n",
      "['the', 'town']\n",
      "{'PLUR': False}\n",
      "['A', 'financial', 'analyst']\n",
      "{'PLUR': False}\n",
      "['securities', 'analyst']\n",
      "{'PLUR': True}\n",
      "['research', 'analyst']\n",
      "{'PLUR': False}\n",
      "['equity', 'analyst']\n",
      "{'PLUR': False}\n",
      "['investment', 'analyst']\n",
      "{'PLUR': False}\n",
      "['The', 'Battle', 'of', 'Kosovo']\n",
      "{'PLUR': False}\n",
      "['the', 'Battle', 'of', 'Kosovo', 'Field']\n",
      "{'PLUR': False}\n",
      "['the', 'Battle', 'of', 'Blackbird', \"'s\", 'Field']\n",
      "{'PLUR': False}\n",
      "['St.', 'Vitus', \"'\", 'Day']\n",
      "{'PLUR': False}\n",
      "['St.', 'Vitus', \"'\", 'Day', ',', 'June', '15', ',', '1389']\n",
      "{'PLUR': False}\n",
      "['Gonzales']\n",
      "{'PLUR': True}\n",
      "['Gonzales', ',', '-LRB-', 'born', 'Jason', 'Charles', 'Beck', ';', '1972', '-RRB-']\n",
      "{'PLUR': True}\n",
      "['Jason', 'Charles', 'Beck']\n",
      "{'PLUR': False}\n",
      "['a', 'Grammy-nominated', 'Canadian', 'musician']\n",
      "{'PLUR': False}\n",
      "['Paris']\n",
      "{'PLUR': False}\n",
      "['Barack', 'Hussein', 'Obama', 'II']\n",
      "{'PLUR': False}\n",
      "['the', '44th', 'and', 'current', 'President', 'of', 'the', 'United', 'States', ',', 'the', 'first', 'African', 'American', 'to', 'hold', 'the', 'office']\n",
      "{'PLUR': True}\n",
      "['President', 'of', 'the', 'United', 'States']\n",
      "{'PLUR': True}\n",
      "['African', 'American']\n",
      "{'PLUR': False}\n",
      "['Honolulu']\n",
      "{'PLUR': False}\n",
      "['FedEx', 'Corporation']\n",
      "{'PLUR': False}\n",
      "['FDX', 'Corporation']\n",
      "{'PLUR': False}\n",
      "['an', 'American', 'global', 'courier', 'delivery', 'services', 'company']\n",
      "{'PLUR': True}\n",
      "['The', 'name', \"''\", 'FedEx', \"''\"]\n",
      "{'PLUR': False}\n",
      "['a', 'syllabic', 'abbreviation', 'of', 'the', 'name', 'of', 'the', 'company', \"'s\", 'original', 'air', 'division', ',', 'Federal', 'Express', ',', 'which', 'was', 'used', 'from', '1973', 'until', '2000']\n",
      "{'PLUR': False}\n",
      "['The', 'University', 'of', 'Sydney']\n",
      "{'PLUR': False}\n",
      "['a', 'public', 'Australian', 'university', 'that', 'is', 'located', 'in', 'Sydney', ',', 'New', 'South', 'Wales']\n",
      "{'PLUR': False}\n",
      "['Sydney']\n",
      "{'PLUR': False}\n",
      "['New', 'South', 'Wales']\n",
      "{'PLUR': False}\n",
      "['The', 'main', 'campus']\n",
      "{'PLUR': False}\n",
      "['Georg', 'Henrik', 'von', 'Wright', '-LRB-', ',', '14', 'June', '1916', '--', '16', 'June', '2003', '-RRB-']\n",
      "{'PLUR': False}\n",
      "['a', 'Finnish', 'philosopher', ',', 'who', 'succeeded', 'Ludwig', 'Wittgenstein', 'as', 'professor', 'at', 'the', 'University', 'of', 'Cambridge']\n",
      "{'PLUR': False}\n",
      "['Ludwig', 'Wittgenstein']\n",
      "{'PLUR': False}\n",
      "['von', 'Wright']\n",
      "{'PLUR': True}\n",
      "['Von', 'Wright', \"'s\"]\n",
      "{'PLUR': False}\n",
      "['The', 'Houston', 'Texans']\n",
      "{'PLUR': True}\n",
      "['a', 'professional', 'American', 'football', 'team', 'based', 'in', 'Houston', ',', 'Texas']\n",
      "{'PLUR': False}\n",
      "['Houston']\n",
      "{'PLUR': False}\n",
      "['The', 'team']\n",
      "{'PLUR': False}\n",
      "['a', 'member', 'of', 'the', 'South', 'Division', 'of', 'the', 'American', 'Football', 'Conference', '-LRB-', 'AFC', '-RRB-', 'in', 'the', 'National', 'Football', 'League', '-LRB-', 'NFL', '-RRB-']\n",
      "{'PLUR': False}\n",
      "['Sir', 'Robert', 'Laird', 'Borden', ',', '-LRB-', 'June', '26', ',', '1854', '--', 'June', '10', ',', '1937', '-RRB-']\n",
      "{'PLUR': False}\n",
      "['June', '10', ',', '1937']\n",
      "{'PLUR': False}\n",
      "['a', 'Canadian', 'lawyer', 'and', 'politician']\n",
      "{'PLUR': False}\n",
      "['the', 'eighth', 'Prime', 'Minister', 'of', 'Canada']\n",
      "{'PLUR': False}\n",
      "['Prime', 'Minister', 'of', 'Canada']\n",
      "{'PLUR': False}\n",
      "['Environmental', 'science']\n",
      "{'PLUR': False}\n",
      "['a', 'multidisciplinary', 'academic', 'field', 'that', 'integrates', 'physical', 'and', 'biological', 'sciences']\n",
      "{'PLUR': True}\n",
      "['biological', 'sciences']\n",
      "{'PLUR': True}\n",
      "['ecology']\n",
      "{'PLUR': False}\n",
      "['physics']\n",
      "{'PLUR': True}\n",
      "['Anatole', 'France']\n",
      "{'PLUR': False}\n",
      "['a', 'French', 'poet', ',', 'journalist', ',', 'and', 'novelist']\n",
      "{'PLUR': False}\n",
      "['Paris']\n",
      "{'PLUR': False}\n",
      "['a', 'successful', 'novelist']\n",
      "{'PLUR': False}\n",
      "['a', 'member', 'of', 'the', 'Académie', 'française']\n",
      "{'PLUR': False}\n",
      "['Johnston', 'Atoll']\n",
      "{'PLUR': False}\n",
      "['a', '1.03', 'sqmi', 'atoll', 'in', 'the', 'North', 'Pacific', 'Ocean', 'about', '750', 'nmi', 'west', 'of', 'Hawaii']\n",
      "{'PLUR': False}\n",
      "['Pacific', 'Ocean']\n",
      "{'PLUR': False}\n",
      "['Hawaii']\n",
      "{'PLUR': False}\n",
      "['The', 'atoll']\n",
      "{'PLUR': False}\n",
      "['The', 'Battle', 'of', 'Wittstock']\n",
      "{'PLUR': False}\n",
      "['Johan', 'Baner']\n",
      "{'PLUR': False}\n",
      "['Johan', 'Baner', 'and', 'Alexander', 'Leslie']\n",
      "{'PLUR': False}\n",
      "['Alexander', 'Leslie']\n",
      "{'PLUR': False}\n",
      "['a', 'combined', 'Imperial-Saxon', 'army']\n",
      "{'PLUR': False}\n",
      "['Jarvis', 'Island']\n",
      "{'PLUR': False}\n",
      "['an', 'uninhabited', '1.75', 'square', 'mile', '-LRB-', '4.5', 'sq', 'kilometer', '-RRB-', 'coral', 'island', 'located', 'in', 'the', 'South', 'Pacific', 'Ocean', 'at', '0', '22', 'S', '160', '01', 'W', ',', 'about', 'halfway', 'between', 'Hawaii', 'and', 'the', 'Cook', 'Islands']\n",
      "{'PLUR': False}\n",
      "['1.75', 'square', 'mile']\n",
      "{'PLUR': False}\n",
      "['4.5', 'sq', 'kilometer']\n",
      "{'PLUR': False}\n",
      "['coral', 'island']\n",
      "{'PLUR': False}\n",
      "['The', 'Concise', 'Oxford', 'English', 'Dictionary']\n",
      "{'PLUR': False}\n",
      "['The', 'Concise', 'Oxford', 'Dictionary']\n",
      "{'PLUR': False}\n",
      "['COD']\n",
      "{'PLUR': False}\n",
      "['The', 'latest', 'edition', 'of', 'the', 'Concise', 'Oxford', 'English', 'Dictionary']\n",
      "{'PLUR': False}\n",
      "['the', 'Concise', 'Oxford', 'English', 'Dictionary']\n",
      "{'PLUR': False}\n",
      "['Crystal', 'Catherine', 'Eastman', '-LRB-', 'June', '25', ',', '1881', '--', 'July', '8', ',', '1928', '-RRB-']\n",
      "{'PLUR': False}\n",
      "['June', '25', ',', '1881']\n",
      "{'PLUR': False}\n",
      "['July', '8', ',', '1928']\n",
      "{'PLUR': False}\n",
      "['a', 'lawyer', ',', 'antimilitarist', ',', 'feminist', ',', 'socialist', ',', 'and', 'journalist']\n",
      "{'PLUR': False}\n",
      "['a', 'leader', 'in', 'the', 'fight', 'for', 'women', \"'s\", 'right', 'to', 'vote']\n",
      "{'PLUR': True}\n",
      "['Longueuil']\n",
      "{'PLUR': False}\n",
      "['a', 'city', 'in', 'the', 'province', 'of', 'Quebec', ',', 'Canada']\n",
      "{'PLUR': False}\n",
      "['the', 'province', 'of', 'Quebec']\n",
      "{'PLUR': False}\n",
      "['Canada']\n",
      "{'PLUR': False}\n",
      "['the', 'seat', 'of', 'the', 'Montérégie', 'administrative', 'region', 'and', 'the', 'central', 'city', 'of', 'the', 'Urban', 'agglomeration', 'of', 'Longueuil']\n",
      "{'PLUR': False}\n",
      "['The', 'Rhodes', 'piano']\n",
      "{'PLUR': False}\n",
      "['an', 'electro-mechanical', 'piano', ',', 'invented', 'by', 'Harold', 'Rhodes', 'during', 'the', '1950s']\n",
      "{'PLUR': True}\n",
      "['Harold', 'Rhodes']\n",
      "{'PLUR': False}\n",
      "['Fender']\n",
      "{'PLUR': False}\n",
      "['1965']\n",
      "{'PLUR': False}\n",
      "['Blood', 'on', 'the', 'Tracks']\n",
      "{'PLUR': True}\n",
      "['the', 'fifteenth', 'studio', 'album', 'by', 'American', 'singer-songwriter', 'Bob', 'Dylan', ',', 'released', 'in', 'January', '1975', 'on', 'Columbia', 'Records']\n",
      "{'PLUR': True}\n",
      "['Bob', 'Dylan']\n",
      "{'PLUR': False}\n",
      "['Columbia', 'Records']\n",
      "{'PLUR': True}\n",
      "['The', 'album']\n",
      "{'PLUR': False}\n",
      "['Michael', 'Mackintosh', 'Foot']\n",
      "{'PLUR': False}\n",
      "['Michael', 'Mackintosh', 'Foot', ',', 'FRSL', ',', 'PC', '-LRB-', '23', 'July', '1913', '--', '3', 'March', '2010', '-RRB-']\n",
      "{'PLUR': False}\n",
      "['3', 'March', '2010']\n",
      "{'PLUR': False}\n",
      "['a', 'British', 'Labour', 'Party', 'politician', 'and', 'man', 'of', 'letters']\n",
      "{'PLUR': True}\n",
      "['British', 'Labour', 'Party']\n",
      "{'PLUR': False}\n",
      "['Aberfoyle']\n",
      "{'PLUR': False}\n",
      "['a', 'village', 'in', 'the', 'region', 'of', 'Stirling', ',', 'Scotland', ',', 'northwest', 'of', 'Glasgow']\n",
      "{'PLUR': False}\n",
      "['Glasgow']\n",
      "{'PLUR': False}\n",
      "['The', 'town']\n",
      "{'PLUR': False}\n",
      "['the', 'River', 'Forth']\n",
      "{'PLUR': False}\n",
      "['Harry', 'Potter', 'and', 'the', 'Chamber', 'of', 'Secrets']\n",
      "{'PLUR': True}\n",
      "['the', 'second', 'novel', 'in', 'the', 'Harry', 'Potter', 'series', 'written', 'by', 'J.', 'K.', 'Rowling']\n",
      "{'PLUR': False}\n",
      "['the', 'Harry', 'Potter', 'series', 'written', 'by', 'J.', 'K.', 'Rowling']\n",
      "{'PLUR': False}\n",
      "['Harry', 'Potter']\n",
      "{'PLUR': False}\n",
      "['J.', 'K.', 'Rowling']\n",
      "{'PLUR': False}\n",
      "['Los', 'Angeles', 'Pierce', 'College']\n",
      "{'PLUR': False}\n",
      "['Pierce', 'College']\n",
      "{'PLUR': False}\n",
      "['Pierce']\n",
      "{'PLUR': False}\n",
      "['a', 'community', 'college', 'that', 'serves', 'more', 'than', '23,000', 'students', 'in', 'the', 'northern', 'Chalk', 'Hills', 'of', 'Woodland', 'Hills', ',', 'a', 'community', 'within', 'the', 'San', 'Fernando', 'Valley', 'region', 'of', 'the', 'city', 'of', 'Los', 'Angeles', ',', 'California']\n",
      "{'PLUR': True}\n",
      "['23,000', 'students']\n",
      "{'PLUR': True}\n",
      "['Eldridge', 'Pope']\n",
      "{'PLUR': False}\n",
      "['a', 'traditional', 'brewery', 'situated', 'in', 'Dorchester', ',', 'Dorset', 'in', 'England']\n",
      "{'PLUR': False}\n",
      "['Dorchester']\n",
      "{'PLUR': False}\n",
      "['Dorset']\n",
      "{'PLUR': False}\n",
      "['The', 'brewery']\n",
      "{'PLUR': False}\n",
      "['The', 'Quasi-War']\n",
      "{'PLUR': False}\n",
      "['an', 'undeclared', 'war', 'fought', 'mostly', 'at', 'sea', 'between', 'the', 'United', 'States', 'and', 'the', 'French', 'Republic', 'from', '1798', 'to', '1800']\n",
      "{'PLUR': True}\n",
      "['the', 'United', 'States']\n",
      "{'PLUR': True}\n",
      "['the', 'French', 'Republic']\n",
      "{'PLUR': False}\n",
      "['the', 'United', 'States']\n",
      "{'PLUR': True}\n",
      "['The', 'Battle', 'of', 'Seneffe']\n",
      "{'PLUR': False}\n",
      "['French', 'army']\n",
      "{'PLUR': False}\n",
      "['French', 'army', 'under', 'the', 'command', 'of', 'Louis', 'II', 'de', 'Bourbon', ',', 'Prince', 'de', 'Condé', 'and', 'the', 'Dutch-German-Spanish', 'army', 'under', 'William', 'III', 'of', 'Orange']\n",
      "{'PLUR': False}\n",
      "['Louis', 'II', 'de', 'Bourbon']\n",
      "{'PLUR': False}\n",
      "['Louis', 'II', 'de', 'Bourbon', ',', 'Prince', 'de', 'Condé']\n",
      "{'PLUR': False}\n",
      "['The', 'Federated', 'States', 'of', 'Micronesia']\n",
      "{'PLUR': True}\n",
      "['The', 'Federated', 'States', 'of', 'Micronesia', '-LRB-', 'FSM', '-RRB-']\n",
      "{'PLUR': True}\n",
      "['FSM']\n",
      "{'PLUR': False}\n",
      "['an', 'independent', 'sovereign', 'island', 'nation', 'consisting', 'of', 'four', 'states', '--', 'from', 'west', 'to', 'east', ',', 'Yap', ',', 'Chuuk', ',', 'Pohnpei', 'and', 'Kosrae', '--', 'that', 'are', 'spread', 'across', 'the', 'Western', 'Pacific', 'Ocean']\n",
      "{'PLUR': True}\n",
      "['four', 'states']\n",
      "{'PLUR': True}\n",
      "['Method', 'of', 'Fluxions']\n",
      "{'PLUR': False}\n",
      "['a', 'book', 'by', 'Isaac', 'Newton']\n",
      "{'PLUR': False}\n",
      "['Isaac', 'Newton']\n",
      "{'PLUR': False}\n",
      "['The', 'book']\n",
      "{'PLUR': False}\n",
      "['Fluxions']\n",
      "{'PLUR': True}\n",
      "['Canada']\n",
      "{'PLUR': False}\n",
      "['a', 'North', 'American', 'country', 'consisting', 'of', 'ten', 'provinces', 'and', 'three', 'territories']\n",
      "{'PLUR': True}\n",
      "['North', 'American']\n",
      "{'PLUR': False}\n",
      "['ten', 'provinces']\n",
      "{'PLUR': True}\n",
      "['ten', 'provinces', 'and', 'three', 'territories']\n",
      "{'PLUR': True}\n"
     ]
    }
   ],
   "source": [
    "check_mention_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5482758620689655"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_anaphor_resolution_system(wikicoref_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "20bf69066c0dd38d51965b69d5e1b6e387082e3198ba56e97997ac55f4e50ad0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
