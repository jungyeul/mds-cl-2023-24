{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COLX 565 Lab Assignment 3: Amazon reviews  (Cheat sheet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment you will\n",
    "- Carefully evaluate approaches to polarity classification using **large** datasets\n",
    "- Do **fine-grained sentiment analysis** with SVM Ranking\n",
    "- Compare automatically-generated scores with gold-standard scores for **profiling Amazon reviewers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code below to access relevant modules (you can add to this as needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#provided code\n",
    "import numpy as np\n",
    "import gzip\n",
    "import random\n",
    "from sklearn.metrics import f1_score\n",
    "from collections import defaultdict\n",
    "from sklearn.svm import LinearSVC, LinearSVR\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.stats import kendalltau\n",
    "from scipy.sparse import vstack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tidy Submission\n",
    "\n",
    "rubric={mechanics:1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the marks for tidy submission:\n",
    "\n",
    "- Submit the assignment by filling in this jupyter notebook with your answers embedded\n",
    "- Be sure to follow the [general lab instructions](https://ubc-mds.github.io/resources_pages/general_lab_instructions)\n",
    "- You should download the Amazon product review corpora but do not include them with your submission. Modify the path below. You also should not unzip them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#provided code\n",
    "amazon_review_dir = \"/MDS2022-2023/COLX_565_sentiment/labs/Lab3/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Download following files**:\n",
    "```\n",
    "wget http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Video_Games_5.json.gz \n",
    "wget http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Beauty_5.json.gz \n",
    "wget http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Cell_Phones_and_Accessories_5.json.gz\n",
    "wget http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Musical_Instruments_5.json.gz\n",
    "```\n",
    "\n",
    "\n",
    "- \"Video Games\" ($>$ 231k), \n",
    "- \"Beauty\" ($>$ 198k), \n",
    "- \"Cell Phones and Accessories\" ($>$ 194k), and \n",
    "- \"Musical Instruments\" ($\\simeq$ 10k instances for testing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Evaluation of polarity classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you'll be building SVM models with collections of amazon reviews. Go to [this site](http://jmcauley.ucsd.edu/data/amazon/index_2014.html) and download the 5-core review sets for the following product types: **\"Video Games\", \"Beauty\", \"Cell Phones and Accessories\", and \"Musical Instruments\"**. You will not actually present any results involving \"Musical Instruments\" in this lab, since the dataset is too small (a mere ten thousand reviews!), but you should use Musical Instruments for testing. For everything else in this lab, you should run things with all three datasets to see if your results are consistent (for the most part, they should be, though with small variations).\n",
    "\n",
    "Each review in the corpus consists of the following information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "{\n",
    "*  \"reviewerID\": \"A2SUAM1J3GNN3B\",\n",
    "*  \"asin\": \"0000013714\",\n",
    "   \"reviewerName\": \"J. McDonald\",\n",
    "   \"helpful\": [2, 3],\n",
    "*  \"reviewText\": \"I bought this for my husband who plays the piano.  He is having a wonderful time playing these old hymns.  The music  is at times hard to read because we think the book was published for singing from more than playing from.  Great purchase though!\",\n",
    "*  \"overall\": 5.0,\n",
    "*  \"summary\": \"Heavenly Highway Hymns\",  <- (TITLE)\n",
    "   \"unixReviewTime\": 1252800000,\n",
    "   \"reviewTime\": \"09 13, 2009\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we will make use of the following aspects of the review: \"reviewText\" (the content of the review), \"summary\" (the title), \"reviewerID\" (a unique identifier indicating who wrote it, \"asin\" (the serial number of the product), and, most importantly, \"overall\", which gives a star rating to the review on a 1-5 scale. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1\n",
    "rubric={accuracy:1,efficiency:1}\n",
    "\n",
    "### `reviews_Musical_Instruments_5.json.gz`\n",
    "\n",
    "Below is some code which loads in **one of the data files** and creates a test set by randomly selecting reviews. We could take everything else as our training set, but we'd like to evaluate our classifier in the context where it cannot take advantage of the biases associated with particular reviewers and products. Your first task is finish this function so it creates a training set (`train_set`) which consists of all the reviews which do not involve *either* a reviewer or a product that appear in the test set (`test_set`)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```train_set = shuffled_corpus - (test_set.reviewerID & test_set.reviewer.asin)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_amazon_reviews_no_dups(corpus_path,test_size=2000,seed=42):\n",
    "    '''loads a gzipped amazon review corpus, sampling a test set of 2000 reviews, with the rest becoming\n",
    "    training provided that they are not reviews of the same product or written by the same reviewers\n",
    "    as training data'''\n",
    "    g = gzip.open(corpus_path, 'r')\n",
    "    all_reviews = [eval(line) for line in g]        ## <- eval()\n",
    "    random.seed(seed)\n",
    "    random.shuffle(all_reviews)\n",
    "    print(\"all_reviews =\", len(all_reviews))\n",
    "    test_set = random.sample(all_reviews, test_size)\n",
    "    \n",
    "    # your code here\n",
    "    # test_products with \"asin\"\n",
    "    # test_reviewers with \"reviewerID\" from test_set\n",
    "    # train_set = shuffled_corpus - (test_set.reviewerID & test_set.reviewer.asin)\n",
    "\n",
    "    print(\"train_set =\", len(train_set), \"test_set =\", len(test_set))\n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to read a *.gz file:\n",
    "g = gzip.open(\"reviews_Beauty_5.json.gz\", 'r')\n",
    "for line in g:\n",
    "    # print(line)\n",
    "    line_byte = line\n",
    "    line_string = eval(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_reviews = 10261\n",
      "train_set = 6100 test_set = 200\n",
      "Success!\n"
     ]
    }
   ],
   "source": [
    "train_set, test_set = load_amazon_reviews_no_dups(amazon_review_dir + \"reviews_Musical_Instruments_5.json.gz\",test_size=200)\n",
    "assert len(train_set) == 6100\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2\n",
    "rubric={accuracy:1,quality:1}\n",
    "\n",
    "Next, we need to prepare the data for sklearn. The provided `prepare_for_classification` uses a CountVectorizer for this purpose. You need to write the `prepare_for_vectorizer` function which should convert the review format into a list of strings (the texts), and the list of *binary* classifications (positive and negative, less than 3 is negative, greater than 3 is positive). You should include both the summary (title) and the body of the review together as the text (with a whitespace delimiter), and you should exclude reviews which have a rating of 3 as being neither positive and negative."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- write the `prepare_for_vectorizer` function which converts the review format into a list of strings, and the list of *binary* classifications: positive if \"overall\" > 3 and negative if \"overall\" < 3\n",
    "- exclude reviews which have a rating of 3 (no neutral)\n",
    "- include the summary (`summary`) and the body of the review (`reviewText`) as the text\n",
    "\n",
    "\n",
    "For example, the example review above should have the following information extracted:\n",
    "\n",
    "```Heavenly Highway Hymns I bought this for my husband who plays the piano.  He is having a wonderful time playing these old hymns.  The music  is at times hard to read because we think the book was published for singing from more than playing from.  Great purchase though!``` should be added to your list of `texts` (note the `Heavenly Highway Hymns` is a summary!), while `pos` should be added to your list of `classifications` (because the review was a 5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "def get_review_text(review):\n",
    "    '''get text for a review by concatenating summary and reviewText from a review dictionary'''\n",
    "    #your code here\n",
    "    # review_text = \"summary\" + \"reviewText\"\n",
    "    return review_text\n",
    "\n",
    "def prepare_for_vectorizer(reviews):\n",
    "    '''extract a list of review texts and a list of binary polarity classifications from the \n",
    "    list of reviews (which are dictionaries)'''\n",
    "    texts = []    \n",
    "    classifications = []\n",
    "    #your code here\n",
    "    # if \"overall\" > 3: positive\n",
    "    # elif \"overall\" < 3: negative\n",
    "    return texts,classifications\n",
    "\n",
    "def prepare_for_classification(train,test,max_n=2):\n",
    "    '''convert lists of reviews train and test to spare feature matrices X_train and X_test,\n",
    "    and lists of binary polarity classifications train_class and test_class'''\n",
    "    vectorizer = CountVectorizer(ngram_range=(1,max_n),min_df=2)\n",
    "    train_texts, train_class = prepare_for_vectorizer(train)\n",
    "    test_texts, test_class = prepare_for_vectorizer(test)\n",
    "    X_train = vectorizer.fit_transform(train_texts)\n",
    "    X_test = vectorizer.transform(test_texts)\n",
    "    return X_train,train_class, X_test,test_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "music_train, train_class, music_test, test_class = prepare_for_classification(train_set,test_set)\n",
    "assert music_train.shape[0] == 5641\n",
    "assert music_train.shape[1] == 57515\n",
    "print(\"Success!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3\n",
    "rubric={accuracy:2,quality:1}\n",
    "\n",
    "Now, using the three large datasets and the functions above (note the `max_n` keyword argument for `prepare_for_classification`), investigate which choice of $n$ gives you the best results for linear SVM $n$-gram models (check n=1,2,3). Since these datasets are imbalanced, you should evaluate with **`macro-averaged f-score`** (https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html) instead of accuracy. You should also print the shape of your training set matrix for each test that you do (they are extremely big!). This will take a while with the main datasets, again you should test it with the smaller one first.... (ie, run it on the `Musical Instruments train / test set`.  Then, when you are happy with the results, you can transfer to **the larger ones**.)  However, note that the results will likely be more stable on the larger datasets, so don't choose \"n\" based on the small one.  Just use the small one for debugging.  On my laptop, each value of `n` takes a couple of minutes to run.  One thing to keep in mind: the `run_tests_maxn` function should create a LinearSVC classifier, train, and evaluate it on each value of `n` from `1` to `max_ns`).  This will help you determine a value of $n$ moving forward.\n",
    "\n",
    "When you having found a reasonable $n$ (if things are close, prefer the lower $n$), use it for the rest of this lab!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`ngram_range=(min_n, max_n)`**: \n",
    "- `(1, 1)` means unigrams\n",
    "- `(1, 2)` means unigrams and bigrams\n",
    "- `(1, 3)` means unigrams, bigrams and trigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `reviews_Video_Games_5.json.gz`\n",
    "### `reviews_Beauty_5.json.gz`\n",
    "### `reviews_Cell_Phones_and_Accessories_5.json.gz`\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "**!!! Running `run_tests_maxn()` takes time for `[\"reviews_Video_Games_5.json.gz\",\"reviews_Beauty_5.json.gz\",\"reviews_Cell_Phones_and_Accessories_5.json.gz\"]`...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_reviews = 231780\n",
      "train_set = 126333 test_set = 2000\n",
      "reviews_Video_Games_5.json.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jungyeul/Library/Python/3.8/lib/python/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(110482, 61609)\n",
      "0.8515814789867693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jungyeul/Library/Python/3.8/lib/python/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "(110482, 998080)\n",
      "0.8953999859847233\n",
      "3\n",
      "(110482, 2687868)\n",
      "0.8874218575726746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jungyeul/Library/Python/3.8/lib/python/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def run_tests_maxn(train,test,max_ns):\n",
    "    '''given a train and test set of reviews, evaluate against the test data when training using using n-grams features for  \n",
    "    each n in max_ns, printing the macro f1'''\n",
    "    # results = []\n",
    "    #your code here\n",
    "    for max_n: # <-- NOTE: this is not a python code\n",
    "        print(max_n)\n",
    "        print(X_train.shape)\n",
    "        print(f1_score(test_class,y_pred,average=\"macro\"))\n",
    "    return ... # nothing to return, actually; \n",
    "\n",
    "for review_filename in [\"reviews_Video_Games_5.json.gz\"]: #[\"reviews_Video_Games_5.json.gz\",\"reviews_Beauty_5.json.gz\",\"reviews_Cell_Phones_and_Accessories_5.json.gz\"]:\n",
    "    train, test = load_amazon_reviews_no_dups(amazon_review_dir + review_filename) \n",
    "    print(review_filename)\n",
    "    run_tests_maxn(train,test,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Optional\n",
    "rubric={viz:1}\n",
    "\n",
    "Investigate the effect of the size of the training data on your classification performance. You will create a line graph containing the results for all three corpora. Your X axis should be logarithmic, and you should check the range from 10 to 100000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_reviews = 231780\n",
      "train_set = 126333 test_set = 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jungyeul/Library/Python/3.8/lib/python/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def run_tests_max_size(train,test,max_sizes):\n",
    "    '''given a train and test set of reviews, evaluate against the test data when trying train_sizes equal to \n",
    "    each sizes in max_sizes, printing the macro f1'''\n",
    "    #your code here\n",
    "    \n",
    "    #your code here\n",
    "    return ...\n",
    "\n",
    "\n",
    "\n",
    "max_sizes = [10,100,1000,10000,100000]\n",
    "\n",
    "#your code here\n",
    "legend = [\"Video Games\",\"Beauty\", \"Cell_Phones_and_Accessories\"]    # note: I'm showing only Video Grames; \n",
    "#your code here\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: SVM Ranking\n",
    "\n",
    "In this exercise, you will compare SVM regression to SVM ranking for predicting fine-grained opinion ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1\n",
    "rubric={accuracy:2,quality:1}\n",
    "\n",
    "First, do the regression version. Relative to what you did in exercise 1, there are three changes\n",
    "\n",
    "- adapt the `prepare_for_classification` and `prepare_for_vectorizer` functions from 1.2 to a `prepare_for_regression` and `prepare_for_vectorizer_regression` functions which no longer convert the data into a binary label.\n",
    "- change the SVC (support vector classifier) to a SVR (support vector regressor)\n",
    "- evaluate the predicted ranks against the original ranks using Kendall's Tau (**to measure the degree of similarity between two rankings**), not f-score\n",
    "\n",
    "As usual, run it for all three datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_vectorizer_regression(reviews):\n",
    "    '''given a list of review dictionaries, convert them to a list of texts and\n",
    "    a list of rating scores in preparation for training a regression model'''\n",
    "    #your code here\n",
    "    scores = []         # no pos/neg; use \"overall\" as it is; \n",
    "    texts = []\n",
    "    # otherwise, copy and paste from 1.2    \n",
    "\n",
    "    return texts,scores\n",
    "\n",
    "def prepare_for_regression(train,test,max_n=2):\n",
    "    '''convert lists of reviews train and test to spare feature matrices X_train and X_test,\n",
    "    and lists of ratings scores for train_class and test_class'''\n",
    "    #your code here\n",
    "    # copy and paste from 1.2 except for `prepare_for_vectorizer_regression`\n",
    "\n",
    "    return X_train,train_scores, X_test,test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for review_filename in     [\"reviews_Musical_Instruments_5.json.gz\"]: #\n",
    "# [\"reviews_Video_Games_5.json.gz\",\"reviews_Beauty_5.json.gz\",\"reviews_Cell_Phones_and_Accessories_5.json.gz\"]:\n",
    "\n",
    "    print(review_filename)\n",
    "    train, test = load_amazon_reviews_no_dups(amazon_review_dir + review_filename) \n",
    "    train_features,train_scores, test_features,test_scores = prepare_for_regression(train,test)\n",
    "    print(\"Training...\")\n",
    "    clf = LinearSVR()\n",
    "    clf.fit(train_features,train_scores)\n",
    "    print(\"Done training...\")\n",
    "    y_pred = clf.predict(test_features)\n",
    "    print(kendalltau(y_pred,test_scores))\n",
    "\n",
    "    # https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.kendalltau.html\n",
    "\n",
    "# For Musical_Instruments_5:\n",
    "# KendalltauResult(correlation=0.11345904958834789, pvalue=1.0091948560881858e-10) \n",
    "# 0.11 indicates between a weak and  medium associations;\n",
    "# P-value <= 0.05: reject the null hypothesis\n",
    "# P-value >  0.05: fail to reject the null hypothesis because there is not enough evidence; \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2\n",
    "rubric={accuracy:3,efficiency:1}\n",
    "\n",
    "Now, you will implement SVMrank using LinearSVC.  The idea behind SVM ranking is that instead of simply predicting a score for a document, the SVM learns **from pairs of reviews**, and whether the rating of the first review is greater than that of the second.  \n",
    "The key is to subtract one review from another: if we have feature vectors for two reviews, [0,1,1,0,0] and [1,0,0,1,1], and scores (1,4), then our pairwise feature vector is [-1,1,1,-1,-1], and the pairwise score is (0) (we subtract, just like with with the features, but we just want to know if it is > 0.  If it is, then the score is (1); otherwise, it is (0)).\n",
    "\n",
    "\n",
    "```\n",
    "[0,1,1,0,0], 1   <-- current datapoint and label\n",
    ".\n",
    ".\n",
    ".\n",
    "[1,0,0,1,1], 4  <-- randomly selected datapoint and label\n",
    "\n",
    "\n",
    "=> [0,1,1,0,0] - [1,0,0,1,1], 1 - 4 = [-1,1,1,-1,-1], 0 <-- 0 if label is not greater than 0. \n",
    "```\n",
    "\n",
    "The main part is to write a function `convert_to_pairwise` which converts the normal output of `prepare_for_regression` and turns it into a (pairwise) classification task using the following logic:\n",
    "\n",
    "- for each original datapoint (feature vector), randomly select one other datapoint that has a different rating (you should keep trying until you get one, don't discard data!)\n",
    "- create a feature vector which is the **difference between the two feature vectors** (subtract)\n",
    "- create a label which should be 1 if the rating of the first datapoint is larger than the second, or 0 if the second rating is larger\n",
    "\n",
    "You should return a new feature matrix (of the same length as the original data) and the corresponding list of labels. Note that you MUST preserve the sparsity of the feature matrix, these matrices are far too big to be densified.\n",
    "\n",
    "This will take a while for the 100k datapoints you have in each corpus, and so you should have a counter that shows your progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_pairwise(data,ratings): #convert_to_pairwise(train_features,train_scores)\n",
    "    '''covert a normal collection of data with ordinal ratings into a pairwise classification task\n",
    "    by randomly choosing one comparison datapoint with a different rating and taking the direction of\n",
    "    the difference as the class of the new datapoint'''\n",
    "    # your code here\n",
    "    new_data = []\n",
    "    pairwise_classes = []\n",
    "    for 0..6100:                            # -> NOTE: not a python code \n",
    "        \n",
    "        while find_a_random_data_point:     # -> NOTE: not a python code\n",
    "            # find a data point where ratings are different:\n",
    "            # if so, append it to new_data\n",
    "            # new_rating (`pairwise_classes`)   1 if ratings[i] > ratings[j]: \n",
    "            #                                   0 if ratings[i] < ratings[j]: \n",
    "\n",
    "\n",
    "\n",
    "    return new_data, pairwise_classes \n",
    "\n",
    "# NOTE: new_data should be data - new_data; \n",
    "# if you do `data - new_data` for each data point, it will take a lot of time (we don't want it); \n",
    "# do at the end before `return` (or during `return`)\n",
    "\n",
    "# it says \"Note that you MUST preserve the sparsity of the feature matrix...\"\n",
    "# SOLUTION: use `vstack` (of sparse, it is NOT numpy `vstack`) for new_data to calcuate `data - new_data`\n",
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.vstack.htmll\n",
    "# >>> A = coo_matrix([[1, 2], [3, 4]])\n",
    "# >>> B = coo_matrix([[5, 6]])\n",
    "# >>> vstack([A, B]).toarray()\n",
    "# array([[1, 2],\n",
    "#        [3, 4],\n",
    "#        [5, 6]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "print(train_features.shape):  (6100, 62003)\n",
    "print(len(train_scores)):     6100\n",
    "print(train_features[0]):\n",
    "  (0, 16219)\t1\n",
    "  (0, 58112)\t1\n",
    "  (0, 23793)\t1\n",
    "  (0, 33837)\t1\n",
    "  (0, 40509)\t1\n",
    "  (0, 39120)\t1\n",
    "  (0, 9033)\t1\n",
    "  (0, 28212)\t1\n",
    "  (0, 53984)\t1\n",
    "  (0, 38973)\t1\n",
    "  (0, 35722)\t1\n",
    "  (0, 23927)\t1\n",
    "  (0, 59593)\t1\n",
    "  (0, 26865)\t1\n",
    "  (0, 18236)\t1\n",
    "  (0, 19338)\t1\n",
    "  (0, 3049)\t1\n",
    "  (0, 53012)\t1\n",
    "  (0, 46165)\t1\n",
    "  (0, 20614)\t1\n",
    "  (0, 23799)\t1\n",
    "  (0, 34085)\t1\n",
    "  (0, 39124)\t1\n",
    "  (0, 9169)\t1\n",
    "  (0, 28384)\t1\n",
    "  (0, 54513)\t1\n",
    "  (0, 39038)\t1\n",
    "  (0, 35733)\t1\n",
    "  (0, 24320)\t1\n",
    "  (0, 59618)\t1\n",
    "  (0, 26929)\t1\n",
    "  (0, 18441)\t1\n",
    "  (0, 19340)\t1\n",
    "  (0, 4202)\t1\n",
    "  (0, 53343)\t1\n",
    "  (0, 46241)\t1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_reviews = 10261\n",
      "train_set = 6100 test_set = 200\n",
      "Success!\n"
     ]
    }
   ],
   "source": [
    "train, test = load_amazon_reviews_no_dups(amazon_review_dir + \"reviews_Musical_Instruments_5.json.gz\",test_size=200) \n",
    "train_features,train_scores, test_features,test_scores = prepare_for_regression(train,test)\n",
    "pairwise_data, pairwise_class = convert_to_pairwise(train_features,train_scores)\n",
    "assert pairwise_data.shape == train_features.shape\n",
    "assert len(set(pairwise_class)) == 2\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6100x62003 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1446303 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairwise_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3\n",
    "rubric={accuracy:2}\n",
    "\n",
    "Use `convert to pairwise` to carry out SVM ranking. Note that although you are converting the training set to pairwise, you don't do this for the test set.  (This takes advantage of a neat trick with SVMs where the training step just learns to assign high weights to binary features that occur in high scores, but not low ones.) \n",
    "Note also that you can't use the `predict` function for the resulting classifier because the result would be a class (ie, 1 or 0, but we want a value between 1 and 5). \n",
    "Instead, you want the result from taking **a dot product of each feature vector and the weights of the SVM classifier (`coef_[0]`)**. Again, evaluate the performance in the 3 corpora using Kendall's tau. You should get strikingly better results as compared to 2.1.  For example, on the Musical Instruments set, I get about 0.11 in 2.1, and 0.22 here.  The p-value is also significantly smaller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reviews_Musical_Instruments_5.json.gz\n",
      "all_reviews = 10261\n",
      "train_set = 237 test_set = 2000\n",
      "KendalltauResult(correlation=0.22420763481123385, pvalue=2.2132732590854616e-37)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jungyeul/Library/Python/3.8/lib/python/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for review_filename in [\"reviews_Musical_Instruments_5.json.gz\"]: #[\"reviews_Video_Games_5.json.gz\",\"reviews_Beauty_5.json.gz\",\"reviews_Cell_Phones_and_Accessories_5.json.gz\"]:\n",
    "    print(review_filename)\n",
    "    #     1. load_amazon_reviews_no_dups() \n",
    "    #     2. prepare_for_regression()\n",
    "    #     3. clf = LinearSVC()\n",
    "    #     4. convert_to_pairwise()\n",
    "    #     5. clf.fit()\n",
    "    #     6. y_pred = test_features.dot(clf.coef_[0])\n",
    "    #     print(kendalltau(y_pred,test_scores))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.35431007,  0.27601938, -0.21696982, ..., -1.22907758,\n",
       "        0.27391499,  0.50317194])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Pollyannas and Negative Nellies\n",
    "rubric={accuracy:3,quality:1}\n",
    "\n",
    "https://en.wikipedia.org/wiki/Pollyanna\n",
    "\n",
    "\n",
    "In this exercise, we are going to see how well our automated system is able to duplicate the conclusions of a simple kind of \"author profiling\" based on gold standard ratings. Two functions are provided to you: the first is `load_amazon_reviews_reviewer_groups` (a variation on `load_amazon_reviews_no_dups`) which creates a test set consisting of reviews written by authors with a total of at least 20 reviews; the training set consists of all other reviews.\n",
    "\n",
    "The second function uses the test set to derive a list of \"Pollyannas\" and \"Negative Nellies\". The former is defined as reviewers who have only given five star reviews, and the latter are those reviewers whose average review rating is below 3 (True Negative Nellies, those who only give 1 star reviews, do not seem to exist! The Pollyanna hypothesis at work yet again...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#provided code\n",
    "review_min = 20\n",
    "\n",
    "def load_amazon_reviews_reviewer_groups(corpus_path,test_size=2000,seed=42):\n",
    "    '''loads a gzipped amazon review corpus and prepares a test set consisting of reviews whose reviewers\n",
    "    has at least 20 total reviews, and the training set consisting of all other reviews'''\n",
    "    g = gzip.open(corpus_path, 'r')\n",
    "    all_reviews = [eval(line) for line in g]\n",
    "    random.seed(seed)\n",
    "    random.shuffle(all_reviews)\n",
    "    train_set = []\n",
    "    test_set = []\n",
    "    reviewer_groups = defaultdict(list)\n",
    "    for i,review in enumerate(all_reviews):\n",
    "        reviewer_groups[review[\"reviewerID\"]].append(review)\n",
    "    for reviewer_group in reviewer_groups.values():\n",
    "        if len(reviewer_group) > review_min:\n",
    "            for review in reviewer_group:\n",
    "                test_set.append(review)\n",
    "        else:\n",
    "            train_set.extend(reviewer_group)\n",
    "        \n",
    "    return train_set,test_set\n",
    "\n",
    "\n",
    "def get_pollyannas_and_nellies(reviews):\n",
    "    '''get a list of pollyannas (reviewers with only 5 star reviews) and negative nellies (those\n",
    "    whose average rating is negative) based on the list of reviews'''\n",
    "    reviewer_ratings = defaultdict(list)\n",
    "    nellies = set()\n",
    "    pollyannas = set()\n",
    "    for review in reviews:\n",
    "        reviewer_ratings[review[\"reviewerID\"]].append(review[\"overall\"])\n",
    "    for reviewer,ratings in reviewer_ratings.items():\n",
    "        avg = sum(ratings)/len(ratings)\n",
    "        if avg < 3:\n",
    "            nellies.add(reviewer)\n",
    "        if avg == 5:\n",
    "            pollyannas.add(reviewer)\n",
    "    return pollyannas,nellies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Use the SVM ranking approach from exercise 2 to derive automatic ratings to the reviews for all reviewers with at least 20 reviews (i.e. the test set provided by `load_amazon_reviews_reviewer_groups`).  Train on the train set you just developed. \n",
    "\n",
    "Then use these ratings to rank the reviewers by the average positivity of their reviews, and see what percentage of the gold standard \"Nellies\" (as identified by `get_pollyannas_and_nellies`) are in the bottom 20% in terms of (automatically-determined) average positivity, and what percentage of gold standard \"Pollyannas\" are in the top 20%.\n",
    "\n",
    "A high score indicates that we are more or less able to re-identify reviewers with strongly positive and negative biases using only automatically-generated review scores. Across the 3 review types, you will do consistently well on one of the types, and noticeably worse on the other (can you guess why?).  Also note that you may run into some issues evaluating on the small dataset this time - there's just too little data; there are no reviewers with 20 reviews that are either all '5's, or all < 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Running the code takes time...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reviews_Video_Games_5.json.gz\n"
     ]
    }
   ],
   "source": [
    "for review_filename in [\"reviews_Video_Games_5.json.gz\"]:\n",
    "    #[\"reviews_Video_Games_5.json.gz\",\"reviews_Beauty_5.json.gz\",\"reviews_Cell_Phones_and_Accessories_5.json.gz\"]:\n",
    "    print(review_filename)\n",
    "    \n",
    "    # prepare the predications:\n",
    "    # use load_amazon_reviews_reviewer_groups() instead of load_amazon_reviews_no_dups() as in Ex2.3. \n",
    "    # otherwise, it will be exactly same as in Ex2.3. \n",
    "    #     1. load_amazon_reviews_reviewer_groups()  \n",
    "    #     2. prepare_for_regression()\n",
    "    #     3. clf = LinearSVC()\n",
    "    #     4. convert_to_pairwise()\n",
    "    #     5. clf.fit()\n",
    "    #     6. y_pred = test_features.dot(clf.coef_[0]) \n",
    "\n",
    "    \n",
    "    # rank the reviewers by average predictions\n",
    "    \n",
    "    # test to see if pollyannas/nellies are in top/bottom 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
